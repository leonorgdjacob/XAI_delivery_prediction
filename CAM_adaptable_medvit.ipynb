{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "Grad-CAM applied to Resnet-18 model for binary classification"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "MQy2-7acwuQb"
      },
      "outputs": [],
      "source": [
        "import os\n",
        "import cv2\n",
        "import torch\n",
        "import pandas as pd\n",
        "import numpy as np\n",
        "from torchvision import transforms\n",
        "from PIL import Image\n",
        "import torchvision.utils as vutils\n",
        "import torchvision.transforms.functional as TF\n",
        "from PIL import Image \n",
        "from MedViT_model import MedViT_base\n",
        "from pytorch_grad_cam import GradCAM, GradCAMPlusPlus, HiResCAM\n",
        "from pytorch_grad_cam.utils.model_targets import ClassifierOutputTarget"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 113,
      "metadata": {},
      "outputs": [],
      "source": [
        "# device\n",
        "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 114,
      "metadata": {
        "id": "MembvQS3w3Bv"
      },
      "outputs": [],
      "source": [
        "# === Function to recreate and load trained MedViT model ===\n",
        "def load_medvit_model(weight_path, num_classes=2, device=torch.device(\"cpu\")):\n",
        "    # Cria modelo com a mesma estrutura usada no treino\n",
        "    model = MedViT_base(pretrained=False, num_classes=1000) #create inference model in the original format\n",
        "\n",
        "    # Carrega pesos do modelo treinado\n",
        "    state_dict = torch.load(weight_path, map_location=device)\n",
        "\n",
        "\n",
        "    in_features = model.proj_head[0].in_features\n",
        "    model.proj_head = torch.nn.Sequential(torch.nn.Linear(in_features, num_classes)) # Ajusta a camada de saída para o número correto de classes\n",
        "    model.load_state_dict(state_dict, strict=False) # Load the state dict with strict=False to ignore the last layer\n",
        "    model.to(device)\n",
        "    model.eval()\n",
        "    #print(model.features[28])\n",
        "    return model\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 115,
      "metadata": {
        "id": "RvYDMrgtDGDo"
      },
      "outputs": [],
      "source": [
        "# Overlay heatmap\n",
        "def overlay_heatmap(original_image, heatmap):\n",
        "    # Debugging: Print heatmap shape and type\n",
        "    #print(f\"[Debug] Initial heatmap shape: {heatmap.shape}, dtype: {heatmap.dtype}\")\n",
        "\n",
        "    # Handle cases where the heatmap has an extra dimension (1, H, W)\n",
        "    if len(heatmap.shape) == 3 and heatmap.shape[0] == 1:\n",
        "        heatmap = np.squeeze(heatmap, axis=0)\n",
        "        #print(f\"[Debug] Squeezed heatmap shape: {heatmap.shape}\")\n",
        "\n",
        "    # Normalize the heatmap to range [0, 1] and convert to uint8\n",
        "    heatmap = np.clip(heatmap, 0, 1)\n",
        "    heatmap_uint8 = np.uint8(255 * heatmap)\n",
        "\n",
        "    # Resize the heatmap to match the original image size\n",
        "    heatmap_resized = cv2.resize(heatmap_uint8, (original_image.shape[1], original_image.shape[0]), interpolation=cv2.INTER_CUBIC)\n",
        "\n",
        "    # Ensure the heatmap is in a compatible format for OpenCV\n",
        "    if len(heatmap_resized.shape) == 2:  # Grayscale heatmap\n",
        "        heatmap_color = cv2.applyColorMap(heatmap_resized, cv2.COLORMAP_JET)\n",
        "    elif len(heatmap_resized.shape) == 3 and heatmap_resized.shape[2] == 1:  # Single channel but 3D\n",
        "        heatmap_color = cv2.applyColorMap(heatmap_resized[:, :, 0], cv2.COLORMAP_JET)\n",
        "    else:\n",
        "        print(f\"[Error] Unexpected heatmap shape after resizing: {heatmap_resized.shape}\")\n",
        "        raise ValueError(\"Heatmap shape is not compatible with cv2.applyColorMap.\")\n",
        "\n",
        "    # Convert grayscale original image to BGR if necessary\n",
        "    if len(original_image.shape) == 2:\n",
        "        original_image = cv2.cvtColor(original_image, cv2.COLOR_GRAY2BGR)\n",
        "\n",
        "    # Blend the heatmap with the original image\n",
        "    overlay = cv2.addWeighted(heatmap_color, 0.4, original_image, 0.6, 0)\n",
        "    return overlay\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 116,
      "metadata": {
        "id": "ceRFezoSDN8p"
      },
      "outputs": [],
      "source": [
        "# === Prediction Frame ===\n",
        "def add_colored_frame(image, color, thickness=20):\n",
        "    height, width = image.shape[:2]\n",
        "    cv2.rectangle(image, (0, 0), (width - 1, height - 1), color, thickness)\n",
        "    return image"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 117,
      "metadata": {},
      "outputs": [],
      "source": [
        "# === Extract Ground Truth from folder path ===\n",
        "def get_ground_truth(img_name, folder):\n",
        "    # Combine the folder path and image name for a comprehensive check\n",
        "    full_path = os.path.join(folder, img_name)\n",
        "    \n",
        "    # Check for the ground truth in a case-insensitive way\n",
        "    #if \"cesarean\" in full_path.lower():  #DESCOMENTAR QUANDO FOR PARA CORRER O COGIDO A PARTIR DO DATASET ORIGINAL\n",
        "    if \"ces\" in full_path.lower():\n",
        "        return \"Cesarean Birth\"\n",
        "    elif \"vag\" in full_path.lower():\n",
        "        return \"Vaginal Birth\"\n",
        "    else:\n",
        "        print(f\"Warning: Could not determine ground truth for {full_path}. Assuming 'Cesarean Birth'.\")\n",
        "        ground_truth = \"Cesarean Birth\"\n",
        "\n",
        "    # Print the ground truth for each image\n",
        "    #print(f\"[Ground Truth] Image: {img_name} | Path: {full_path} | Picked: {ground_truth}\")\n",
        "    return ground_truth"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "UwB2aywJDQog"
      },
      "outputs": [],
      "source": [
        "def apply_gradcam_and_save(model, input_folder, output_folder, grid_image_size=(224, 224)):\n",
        "    os.makedirs(output_folder, exist_ok=True)\n",
        "    \n",
        "    target_layers = [model.features[28]]\n",
        "\n",
        "\n",
        "    transform = transforms.Compose([\n",
        "        transforms.Resize((224, 224)), # Correct input size\n",
        "        transforms.ToTensor(),\n",
        "        transforms.Normalize(mean=[0.5, 0.5, 0.5], std=[0.5, 0.5, 0.5])  # Normalize for 1 channel \n",
        "    ])\n",
        "\n",
        "    original_images = []\n",
        "    correct_heatmaps = []\n",
        "    incorrect_heatmaps = []\n",
        "    misclassified_tensors = []\n",
        "    correctly_classified_tensors = []\n",
        "    #prediction_results = []\n",
        "\n",
        "    class_names = [\"Cesarean Birth\", \"Vaginal Birth\"]\n",
        "\n",
        "    for img_name in os.listdir(input_folder):\n",
        "        if not img_name.lower().endswith((\".png\")):\n",
        "            continue\n",
        "\n",
        "        img_path = os.path.join(input_folder, img_name)\n",
        "        image = Image.open(img_path).convert(\"RGB\") \n",
        "\n",
        "        \n",
        "        input_tensor = transform(image).unsqueeze(0).to(device)\n",
        "        # Save the resized image as original (224x224) to ensure overlay consistency\n",
        "        resized_image = transforms.Resize((224, 224))(image)\n",
        "        original_np = np.array(resized_image)\n",
        "        original_images.append(original_np)\n",
        "\n",
        "\n",
        "        # Previsão para obter classe\n",
        "        with torch.no_grad():\n",
        "            output = model(input_tensor)\n",
        "            prediction = output.argmax(dim=1).item()\n",
        "            probabilities = torch.softmax(output, dim=1)\n",
        "            confidence = probabilities[0, prediction].item()\n",
        "\n",
        "        # Grad-CAM\n",
        "        with HiResCAM(model=model, target_layers=target_layers) as cam:  \n",
        "            targets = [ClassifierOutputTarget(prediction)]\n",
        "            grayscale_cam = cam(input_tensor=input_tensor, targets=targets)[0]  # [H, W]\n",
        "\n",
        "\n",
        "        # === Ground truth from folder name ===\n",
        "        ground_truth_label = get_ground_truth(img_name, input_folder)\n",
        "        ground_truth_class = class_names.index(ground_truth_label)\n",
        "\n",
        "        # Add frame\n",
        "        frame_color = (0, 255, 0)  # green\n",
        "        if prediction != ground_truth_class:\n",
        "            frame_color = (0, 0, 255)  # red\n",
        "\n",
        "        # === Overlay and save ===\n",
        "        overlay = overlay_heatmap(original_np, grayscale_cam[np.newaxis, ...])  # adiciona dimensão extra\n",
        "        overlay_with_frame = add_colored_frame(overlay, frame_color, thickness=7)\n",
        "\n",
        "        # === Save heatmap image ===\n",
        "        save_path = os.path.join(output_folder, f\"heatmap_{class_names[prediction]}_{img_name}\")\n",
        "        cv2.imwrite(save_path, overlay_with_frame)\n",
        "\n",
        "        # === Save heatmap for mean and tensor for grid ===\n",
        "        overlay_rgb = cv2.cvtColor(overlay_with_frame, cv2.COLOR_BGR2RGB) #converts to rgb\n",
        "        overlay_pil = Image.fromarray(overlay_rgb).resize(grid_image_size) # downsizes the image to fit the grid\n",
        "        tensor_for_grid = TF.to_tensor(overlay_pil) #converts into a pytorch tensor [3,H,W] and normalizes pixel values\n",
        "\n",
        "        if prediction == ground_truth_class:\n",
        "            correctly_classified_tensors.append(tensor_for_grid)\n",
        "            correct_heatmaps.append(grayscale_cam)  # 2D spatial heatmap , cam shape = [7,7]\n",
        "        else:\n",
        "            misclassified_tensors.append(tensor_for_grid)\n",
        "            incorrect_heatmaps.append(grayscale_cam)\n",
        "\n",
        "\n",
        "    # === CREATE GRID ===\n",
        "    final_sorted_grid = misclassified_tensors + correctly_classified_tensors\n",
        "    if final_sorted_grid:\n",
        "        grid = vutils.make_grid(final_sorted_grid, nrow=20, padding=5, normalize=True)\n",
        "        grid_path = os.path.join(output_folder, \"grid_overlay_ordered.jpg\")\n",
        "        vutils.save_image(grid, grid_path)\n",
        "        #print(f\"Grid saved at: {grid_path}\")\n",
        "\n",
        "    # === CALCULATE CORRECT MEAN HEATMAP ===\n",
        "    if correct_heatmaps: #list of NumPy arrays (raw grad-cam maps before resizing or coloring), each w\\ shape [3, 3]\n",
        "        mean_heatmap = np.mean(np.stack(correct_heatmaps), axis=0) # turns list of N heatmaps into 3D array w\\ shape [N, 7, 7]\n",
        "        mean_heatmap -= mean_heatmap.min() # subtracts the minimum value from every pixel so the lowest value is 0\n",
        "        mean_heatmap /= (mean_heatmap.max() + 1e-8) # divides every pixel by the new maximum value (normalize) ; adds 1e-8 to ensure it wont be divided by 0\n",
        "        heatmap_uint8 = np.uint8(255 * mean_heatmap) # Converts [0.0 – 1.0] → [0 – 255] format needed for OpenCV\n",
        "        heatmap_colored = cv2.applyColorMap(heatmap_uint8, cv2.COLORMAP_JET) # assigns color to the values\n",
        "\n",
        "        # Resize to match original image size\n",
        "        h, w = original_images[0].shape[:2]\n",
        "        heatmap_resized_blocky = cv2.resize(heatmap_colored, (w, h), interpolation=cv2.INTER_NEAREST) #INTER_CUBIC for smoother transitions ; INTER_NEAREST for blocky look\n",
        "        heatmap_resized_smooth = cv2.resize(heatmap_colored, (w, h), interpolation=cv2.INTER_CUBIC)\n",
        "\n",
        "\n",
        "        mean_path_blocky = os.path.join(output_folder, \"correct_mean_heatmap_blocky.png\")\n",
        "        cv2.imwrite(mean_path_blocky, heatmap_resized_blocky)\n",
        "        #print(f\"Mean heatmap (correct only) saved at: {mean_path_blocky}\")\n",
        "\n",
        "        mean_path_smooth = os.path.join(output_folder, \"correct_mean_smooth.png\")\n",
        "        cv2.imwrite(mean_path_smooth, heatmap_resized_smooth)\n",
        "        #print(f\"Mean heatmap (correct only) saved at: {mean_path_smooth}\")\n",
        "\n",
        "    # === CALCULATE INCORRECT MEAN HEATMAP ===\n",
        "    if incorrect_heatmaps:\n",
        "        mean_heatmap_incorrect = np.mean(np.stack(incorrect_heatmaps), axis=0)\n",
        "        mean_heatmap_incorrect -= mean_heatmap_incorrect.min()\n",
        "        mean_heatmap_incorrect /= (mean_heatmap_incorrect.max() + 1e-8)\n",
        "        heatmap_uint8_incorrect = np.uint8(255 * mean_heatmap_incorrect)\n",
        "        heatmap_colored_incorrect = cv2.applyColorMap(heatmap_uint8_incorrect, cv2.COLORMAP_JET)\n",
        "\n",
        "        h, w = original_images[0].shape[:2]\n",
        "        heatmap_resized_blocky_incorrect = cv2.resize(heatmap_colored_incorrect, (w, h), interpolation=cv2.INTER_NEAREST)\n",
        "        heatmap_resized_smooth_incorrect = cv2.resize(heatmap_colored_incorrect, (w, h), interpolation=cv2.INTER_CUBIC)\n",
        "\n",
        "        mean_path_blocky_incorrect = os.path.join(output_folder, \"incorrect_mean_heatmap_blocky.png\")\n",
        "        cv2.imwrite(mean_path_blocky_incorrect, heatmap_resized_blocky_incorrect)\n",
        "        print(f\"Mean heatmap (incorrect only) saved at: {mean_path_blocky_incorrect}\")\n",
        "\n",
        "        mean_path_smooth_incorrect = os.path.join(output_folder, \"incorrect_mean_smooth.png\")\n",
        "        cv2.imwrite(mean_path_smooth_incorrect, heatmap_resized_smooth_incorrect)\n",
        "        print(f\"Mean heatmap (incorrect only) saved at: {mean_path_smooth_incorrect}\")\n",
        "\n",
        "\n",
        "    return correct_heatmaps, original_images"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 119,
      "metadata": {},
      "outputs": [
        {
          "data": {
            "text/plain": [
              "'def generate_prediction_table_only(model, input_folder, split_name, structure, birth_type, dataset):\\n    transform = transforms.Compose([\\n        transforms.Resize((224, 224)),\\n        transforms.ToTensor(),\\n        transforms.Normalize(mean=[0.5, 0.5, 0.5], std=[0.5, 0.5, 0.5])\\n    ])\\n\\n    class_names = [\"Cesarean Birth\", \"Vaginal Birth\"]\\n    prediction_results = []\\n\\n    for img_name in os.listdir(input_folder):\\n        if not img_name.lower().endswith(\".png\"):\\n            continue\\n\\n        img_path = os.path.join(input_folder, img_name)\\n        image = Image.open(img_path).convert(\"RGB\")\\n        input_tensor = transform(image).unsqueeze(0).to(device)\\n\\n        with torch.no_grad():\\n            output = model(input_tensor)\\n            prediction = output.argmax(dim=1).item()\\n            probabilities = torch.softmax(output, dim=1)\\n            confidence = probabilities[0, prediction].item()\\n\\n        ground_truth_label = get_ground_truth(img_name, input_folder)\\n        ground_truth_class = class_names.index(ground_truth_label)\\n\\n        prediction_results.append({\\n            \"Image\": img_name,\\n            \"Predicted Class\": class_names[prediction],\\n            \"Ground Truth\": ground_truth_label,\\n            \"Correct\": prediction == ground_truth_class,\\n            \"Confidence\": round(confidence, 4),\\n            \"Split\": split_name,\\n            \"Structure\": structure,\\n            \"Birth Type\": birth_type,\\n            \"Dataset\": dataset\\n        })\\n\\n    return pd.DataFrame(prediction_results)'"
            ]
          },
          "execution_count": 119,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "\"\"\"def generate_prediction_table_only(model, input_folder, split_name, structure, birth_type, dataset):\n",
        "    transform = transforms.Compose([\n",
        "        transforms.Resize((224, 224)),\n",
        "        transforms.ToTensor(),\n",
        "        transforms.Normalize(mean=[0.5, 0.5, 0.5], std=[0.5, 0.5, 0.5])\n",
        "    ])\n",
        "\n",
        "    class_names = [\"Cesarean Birth\", \"Vaginal Birth\"]\n",
        "    prediction_results = []\n",
        "\n",
        "    for img_name in os.listdir(input_folder):\n",
        "        if not img_name.lower().endswith(\".png\"):\n",
        "            continue\n",
        "\n",
        "        img_path = os.path.join(input_folder, img_name)\n",
        "        image = Image.open(img_path).convert(\"RGB\")\n",
        "        input_tensor = transform(image).unsqueeze(0).to(device)\n",
        "\n",
        "        with torch.no_grad():\n",
        "            output = model(input_tensor)\n",
        "            prediction = output.argmax(dim=1).item()\n",
        "            probabilities = torch.softmax(output, dim=1)\n",
        "            confidence = probabilities[0, prediction].item()\n",
        "\n",
        "        ground_truth_label = get_ground_truth(img_name, input_folder)\n",
        "        ground_truth_class = class_names.index(ground_truth_label)\n",
        "\n",
        "        prediction_results.append({\n",
        "            \"Image\": img_name,\n",
        "            \"Predicted Class\": class_names[prediction],\n",
        "            \"Ground Truth\": ground_truth_label,\n",
        "            \"Correct\": prediction == ground_truth_class,\n",
        "            \"Confidence\": round(confidence, 4),\n",
        "            \"Split\": split_name,\n",
        "            \"Structure\": structure,\n",
        "            \"Birth Type\": birth_type,\n",
        "            \"Dataset\": dataset\n",
        "        })\n",
        "\n",
        "    return pd.DataFrame(prediction_results)\"\"\""
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 120,
      "metadata": {},
      "outputs": [
        {
          "data": {
            "text/plain": [
              "'\\ndef main2():\\n    print(\"Início do processamento...\")\\n    # Caminho base onde estão as pastas\\n    base_folder = \"C:/Users/anale/OneDrive/Documentos/Universidade/TESE/RESULTS/Grad_MEDVIT/medvit_image-dataset_confidence_sorted/medvit_image_dataset_cv3_confidence_sorted\"\\n    print(\"Base folder:\", base_folder)\\n    print(\"Pastas encontradas:\", os.listdir(base_folder))\\n\\n    # Caminho para os pesos\\n    base_weight = \"C:/Users/anale/OneDrive/Documentos/Universidade/TESE/model_paths/MedViT_paths/{structure}_cv3_medvit_pretrained_best-model.pth\"\\n\\n    # Mapear estruturas para nome limpo usado nos pesos\\n    structure_map = {\\n        \"abdomen\": \"abdomen\",\\n        \"femur\": \"femur\",\\n        \"head\": \"head\"\\n    }\\n\\n    # Percorrer todas as pastas no diretório base\\n    for pasta_nome in os.listdir(base_folder):\\n        pasta_path = os.path.join(base_folder, pasta_nome)\\n        if not os.path.isdir(pasta_path):\\n            continue\\n\\n        try:\\n            estrutura, parto, dataset, *_ = pasta_nome.split(\"_\")\\n        except ValueError:\\n            print(f\"[ERRO] Nome inválido: {pasta_nome}\")\\n            continue\\n\\n        estrutura_clean = structure_map.get(estrutura.lower())\\n        if not estrutura_clean:\\n            print(f\"[ERRO] Estrutura não reconhecida: {estrutura}\")\\n            continue\\n        \\n        # Construir caminho do modelo\\n        weight_path = base_weight.format(structure=estrutura_clean)\\n        print(f\"→ Weight path: {weight_path}\")\\n        if not os.path.exists(weight_path):\\n            print(f\"[SKIPPED] Peso não encontrado: {weight_path}\")\\n            continue\\n\\n        print(f\"[PROCESSING] Pasta: {pasta_nome}\")\\n        model = load_medvit_model(weight_path, num_classes=2)\\n\\n        # Aplicar Grad-CAM e guardar outputs na própria pasta\\n        apply_gradcam_and_save(model, pasta_path, pasta_path)\\n\\n    print(\"✅ Processamento concluído para todas as pastas.\")\\n\\nif __name__ == \"__main__\":\\n    main2()\\n\\n'"
            ]
          },
          "execution_count": 120,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "#APARA CORRER APENAS IMAGENS DE MAIOR E MENOR CONFIANÇA SELECIONADAS\n",
        "\"\"\"\n",
        "def main2():\n",
        "    print(\"Início do processamento...\")\n",
        "    # Caminho base onde estão as pastas\n",
        "    base_folder = \"C:/Users/anale/OneDrive/Documentos/Universidade/TESE/RESULTS/Grad_MEDVIT/medvit_image-dataset_confidence_sorted/medvit_image_dataset_cv3_confidence_sorted\"\n",
        "    print(\"Base folder:\", base_folder)\n",
        "    print(\"Pastas encontradas:\", os.listdir(base_folder))\n",
        "\n",
        "    # Caminho para os pesos\n",
        "    base_weight = \"C:/Users/anale/OneDrive/Documentos/Universidade/TESE/model_paths/MedViT_paths/{structure}_cv3_medvit_pretrained_best-model.pth\"\n",
        "\n",
        "    # Mapear estruturas para nome limpo usado nos pesos\n",
        "    structure_map = {\n",
        "        \"abdomen\": \"abdomen\",\n",
        "        \"femur\": \"femur\",\n",
        "        \"head\": \"head\"\n",
        "    }\n",
        "\n",
        "    # Percorrer todas as pastas no diretório base\n",
        "    for pasta_nome in os.listdir(base_folder):\n",
        "        pasta_path = os.path.join(base_folder, pasta_nome)\n",
        "        if not os.path.isdir(pasta_path):\n",
        "            continue\n",
        "\n",
        "        try:\n",
        "            estrutura, parto, dataset, *_ = pasta_nome.split(\"_\")\n",
        "        except ValueError:\n",
        "            print(f\"[ERRO] Nome inválido: {pasta_nome}\")\n",
        "            continue\n",
        "\n",
        "        estrutura_clean = structure_map.get(estrutura.lower())\n",
        "        if not estrutura_clean:\n",
        "            print(f\"[ERRO] Estrutura não reconhecida: {estrutura}\")\n",
        "            continue\n",
        "        \n",
        "        # Construir caminho do modelo\n",
        "        weight_path = base_weight.format(structure=estrutura_clean)\n",
        "        print(f\"→ Weight path: {weight_path}\")\n",
        "        if not os.path.exists(weight_path):\n",
        "            print(f\"[SKIPPED] Peso não encontrado: {weight_path}\")\n",
        "            continue\n",
        "\n",
        "        print(f\"[PROCESSING] Pasta: {pasta_nome}\")\n",
        "        model = load_medvit_model(weight_path, num_classes=2)\n",
        "\n",
        "        # Aplicar Grad-CAM e guardar outputs na própria pasta\n",
        "        apply_gradcam_and_save(model, pasta_path, pasta_path)\n",
        "\n",
        "    print(\"✅ Processamento concluído para todas as pastas.\")\n",
        "\n",
        "if __name__ == \"__main__\":\n",
        "    main2()\n",
        "\n",
        "\"\"\""
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Processing: Abdomen_, Cesarean Birth, train, cv3\n",
            "initialize_weights...\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "C:\\Users\\anale\\AppData\\Local\\Temp\\ipykernel_16272\\587674426.py:7: FutureWarning: You are using `torch.load` with `weights_only=False` (the current default value), which uses the default pickle module implicitly. It is possible to construct malicious pickle data which will execute arbitrary code during unpickling (See https://github.com/pytorch/pytorch/blob/main/SECURITY.md#untrusted-models for more details). In a future release, the default value for `weights_only` will be flipped to `True`. This limits the functions that could be executed during unpickling. Arbitrary objects will no longer be allowed to be loaded via this mode unless they are explicitly allowlisted by the user via `torch.serialization.add_safe_globals`. We recommend you start setting `weights_only=True` for any use case where you don't have full control of the loaded file. Please open an issue on GitHub for any issues related to this experimental feature.\n",
            "  state_dict = torch.load(weight_path, map_location=device)\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Processing: Abdomen_, Cesarean Birth, test, cv3\n",
            "initialize_weights...\n",
            "Mean heatmap (incorrect only) saved at: C:/Users/anale/OneDrive/Documentos/Universidade/TESE/RESULTS/HiRes_MEDVIT/HiRes_medvit_cv3_results/X_hires_medvit_abdomen_cesarean_test_cv3\\incorrect_mean_heatmap_blocky.png\n",
            "Mean heatmap (incorrect only) saved at: C:/Users/anale/OneDrive/Documentos/Universidade/TESE/RESULTS/HiRes_MEDVIT/HiRes_medvit_cv3_results/X_hires_medvit_abdomen_cesarean_test_cv3\\incorrect_mean_smooth.png\n",
            "Processing: Abdomen_, Vaginal Birth, train, cv3\n",
            "initialize_weights...\n",
            "Processing: Abdomen_, Vaginal Birth, test, cv3\n",
            "initialize_weights...\n",
            "Mean heatmap (incorrect only) saved at: C:/Users/anale/OneDrive/Documentos/Universidade/TESE/RESULTS/HiRes_MEDVIT/HiRes_medvit_cv3_results/X_hires_medvit_abdomen_vaginal_test_cv3\\incorrect_mean_heatmap_blocky.png\n",
            "Mean heatmap (incorrect only) saved at: C:/Users/anale/OneDrive/Documentos/Universidade/TESE/RESULTS/HiRes_MEDVIT/HiRes_medvit_cv3_results/X_hires_medvit_abdomen_vaginal_test_cv3\\incorrect_mean_smooth.png\n"
          ]
        },
        {
          "ename": "",
          "evalue": "",
          "output_type": "error",
          "traceback": [
            "\u001b[1;31mThe Kernel crashed while executing code in the current cell or a previous cell. \n",
            "\u001b[1;31mPlease review the code in the cell(s) to identify a possible cause of the failure. \n",
            "\u001b[1;31mClick <a href='https://aka.ms/vscodeJupyterKernelCrash'>here</a> for more info. \n",
            "\u001b[1;31mView Jupyter <a href='command:jupyter.viewOutput'>log</a> for further details."
          ]
        }
      ],
      "source": [
        "def main():\n",
        "    #only_generate_csv = True  # <-- MUDA AQUI\n",
        "\n",
        "    structures = [\"Abdomen_\"] #,\"Femur_\", \"Head_\"] \n",
        "    birth_types = [\"Cesarean Birth\", \"Vaginal Birth\"]\n",
        "    datasets = [\"train\", \"test\"]\n",
        "    splits = [\"cv3\"] #[\"cv1\", \"cv2\",\"cv3\"]\n",
        "\n",
        "    dfs_by_split = {split: {} for split in splits}  # dict de dicts\n",
        "\n",
        "    base_input = \"C:/Users/anale/OneDrive/Documentos/Universidade/TESE/image-dataset/dataset_images_{split}/{structure}/{dataset}/{birth_type}\"\n",
        "    base_output = \"C:/Users/anale/OneDrive/Documentos/Universidade/TESE/RESULTS/HiRes_MEDVIT/HiRes_medvit_{split}_results/X_hires_medvit_{structure_clean}_{birth_type_short}_{dataset}_{split}\" \n",
        "    base_weight = \"C:/Users/anale/OneDrive/Documentos/Universidade/TESE/model_paths/MedViT_paths/{structure_clean}_{split}_medvit_pretrained_best-model.pth\"\n",
        "    output_dir = \"C:/Users/anale/OneDrive/Documentos/Universidade/TESE/RESULTS/prediction_confidence_medvit_xlsx\"\n",
        "    os.makedirs(output_dir, exist_ok=True)\n",
        "\n",
        "\n",
        "    for split in splits:\n",
        "        for structure in structures:\n",
        "            structure_clean = structure.rstrip(\"_\").lower()\n",
        "            for birth_type in birth_types:\n",
        "                birth_type_short = birth_type.split()[0].lower()  # 'cesarean' or 'vaginal'\n",
        "                for dataset in datasets:\n",
        "                    input_folder = base_input.format(split=split, structure=structure, birth_type=birth_type, dataset=dataset)\n",
        "                    output_folder = base_output.format(split=split, structure_clean=structure_clean, birth_type_short=birth_type_short, dataset=dataset)\n",
        "                    weight_path = base_weight.format(structure_clean=structure_clean, split=split)\n",
        "\n",
        "                    if not os.path.exists(weight_path):\n",
        "                        print(f\"[SKIPPED] Weight file does not exist: {weight_path}\")\n",
        "                        continue\n",
        "\n",
        "                    print(f\"Processing: {structure}, {birth_type}, {dataset}, {split}\")\n",
        "                    model = load_medvit_model(weight_path, num_classes=2)\n",
        "                    all_heatmaps, original_images = apply_gradcam_and_save(model, input_folder, output_folder)\n",
        "\n",
        "                    df = generate_prediction_table_only(\n",
        "                            model=model,\n",
        "                            input_folder=input_folder,\n",
        "                            split_name=split,\n",
        "                            structure=structure_clean,\n",
        "                            birth_type=birth_type_short,\n",
        "                            dataset=dataset\n",
        "                    )\n",
        "                    \n",
        "                    sheet_name = f\"{structure_clean}_{birth_type_short}_{dataset}\"[:31]\n",
        "                    dfs_by_split[split][sheet_name] = df\n",
        "\n",
        "    # === Guardar cada split como um ficheiro .xlsx ===\n",
        "    for split, sheet_dict in dfs_by_split.items():\n",
        "        excel_path = os.path.join(output_dir, f\"{split}.xlsx\")\n",
        "        with pd.ExcelWriter(excel_path, engine=\"openpyxl\") as writer:\n",
        "            for sheet_name, df in sheet_dict.items():\n",
        "                df.to_excel(writer, sheet_name=sheet_name, index=False)\n",
        "        print(f\"Guardado: {excel_path}\")\n",
        "\n",
        "    print(\"All Grad-CAM heatmaps were generated successfully.\")\n",
        "\n",
        "if __name__ == \"__main__\":\n",
        "    main() \n"
      ]
    }
  ],
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "display_name": "leonorjacob-tese",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.10.16"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
