{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "Grad-CAM applied to Resnet-18 model for binary classification"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "id": "MQy2-7acwuQb"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            ">>> [MedViT DEBUG] Loaded this exact file!\n"
          ]
        }
      ],
      "source": [
        "import os\n",
        "import cv2\n",
        "import torch\n",
        "import numpy as np\n",
        "from torchvision import transforms\n",
        "import torchvision.utils as vutils\n",
        "import torchvision.transforms.functional as TF\n",
        "from PIL import Image \n",
        "from MedViT_model import MedViT_base\n",
        "from pytorch_grad_cam import GradCAM, GradCAMPlusPlus, HiResCAM\n",
        "from pytorch_grad_cam.utils.model_targets import ClassifierOutputTarget"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "metadata": {},
      "outputs": [],
      "source": [
        "# device\n",
        "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 3,
      "metadata": {
        "id": "MembvQS3w3Bv"
      },
      "outputs": [],
      "source": [
        "# === Function to recreate and load trained MedViT model ===\n",
        "def load_medvit_model(weight_path, num_classes=2, device=torch.device(\"cpu\")):\n",
        "    # Cria modelo com a mesma estrutura usada no treino\n",
        "    model = MedViT_base(pretrained=False, num_classes=1000) #create inference model in the original format\n",
        "\n",
        "    # Carrega pesos do modelo treinado\n",
        "    state_dict = torch.load(weight_path, map_location=device)\n",
        "\n",
        "\n",
        "    in_features = model.proj_head[0].in_features\n",
        "    model.proj_head = torch.nn.Sequential(torch.nn.Linear(in_features, num_classes)) # Ajusta a camada de saída para o número correto de classes\n",
        "    model.load_state_dict(state_dict, strict=False) # Load the state dict with strict=False to ignore the last layer\n",
        "    model.to(device)\n",
        "    model.eval()\n",
        "    print(model.features)\n",
        "    return model\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 4,
      "metadata": {
        "id": "RvYDMrgtDGDo"
      },
      "outputs": [],
      "source": [
        "# Overlay heatmap\n",
        "def overlay_heatmap(original_image, heatmap):\n",
        "    # Debugging: Print heatmap shape and type\n",
        "    #print(f\"[Debug] Initial heatmap shape: {heatmap.shape}, dtype: {heatmap.dtype}\")\n",
        "\n",
        "    # Handle cases where the heatmap has an extra dimension (1, H, W)\n",
        "    if len(heatmap.shape) == 3 and heatmap.shape[0] == 1:\n",
        "        heatmap = np.squeeze(heatmap, axis=0)\n",
        "        #print(f\"[Debug] Squeezed heatmap shape: {heatmap.shape}\")\n",
        "\n",
        "    # Normalize the heatmap to range [0, 1] and convert to uint8\n",
        "    heatmap = np.clip(heatmap, 0, 1)\n",
        "    heatmap_uint8 = np.uint8(255 * heatmap)\n",
        "\n",
        "    # Resize the heatmap to match the original image size\n",
        "    heatmap_resized = cv2.resize(heatmap_uint8, (original_image.shape[1], original_image.shape[0]), interpolation=cv2.INTER_CUBIC)\n",
        "\n",
        "    # Ensure the heatmap is in a compatible format for OpenCV\n",
        "    if len(heatmap_resized.shape) == 2:  # Grayscale heatmap\n",
        "        heatmap_color = cv2.applyColorMap(heatmap_resized, cv2.COLORMAP_JET)\n",
        "    elif len(heatmap_resized.shape) == 3 and heatmap_resized.shape[2] == 1:  # Single channel but 3D\n",
        "        heatmap_color = cv2.applyColorMap(heatmap_resized[:, :, 0], cv2.COLORMAP_JET)\n",
        "    else:\n",
        "        print(f\"[Error] Unexpected heatmap shape after resizing: {heatmap_resized.shape}\")\n",
        "        raise ValueError(\"Heatmap shape is not compatible with cv2.applyColorMap.\")\n",
        "\n",
        "    # Convert grayscale original image to BGR if necessary\n",
        "    if len(original_image.shape) == 2:\n",
        "        original_image = cv2.cvtColor(original_image, cv2.COLOR_GRAY2BGR)\n",
        "\n",
        "    # Blend the heatmap with the original image\n",
        "    overlay = cv2.addWeighted(heatmap_color, 0.4, original_image, 0.6, 0)\n",
        "    return overlay\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 5,
      "metadata": {
        "id": "ceRFezoSDN8p"
      },
      "outputs": [],
      "source": [
        "# === Prediction Frame ===\n",
        "def add_colored_frame(image, color, thickness=20):\n",
        "    height, width = image.shape[:2]\n",
        "    cv2.rectangle(image, (0, 0), (width - 1, height - 1), color, thickness)\n",
        "    return image"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 6,
      "metadata": {},
      "outputs": [],
      "source": [
        "# === Extract Ground Truth from folder path ===\n",
        "def get_ground_truth(img_name, folder):\n",
        "    # Combine the folder path and image name for a comprehensive check\n",
        "    full_path = os.path.join(folder, img_name)\n",
        "    \n",
        "    # Check for the ground truth in a case-insensitive way\n",
        "    #if \"cesarean\" in full_path.lower():  #DESCOMENTAR QUANDO FOR PARA CORRER O COGIDO A PARTIR DO DATASET ORIGINAL\n",
        "    if \"ces\" in full_path.lower():\n",
        "        return \"Cesarean Birth\"\n",
        "    elif \"vag\" in full_path.lower():\n",
        "        return \"Vaginal Birth\"\n",
        "    else:\n",
        "        print(f\"Warning: Could not determine ground truth for {full_path}. Assuming 'Cesarean Birth'.\")\n",
        "        ground_truth = \"Cesarean Birth\"\n",
        "\n",
        "    # Print the ground truth for each image\n",
        "    #print(f\"[Ground Truth] Image: {img_name} | Path: {full_path} | Picked: {ground_truth}\")\n",
        "    return ground_truth"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 7,
      "metadata": {
        "id": "UwB2aywJDQog"
      },
      "outputs": [],
      "source": [
        "def apply_gradcam_and_save(model, input_folder, output_folder, grid_image_size=(224, 224)):\n",
        "    os.makedirs(output_folder, exist_ok=True)\n",
        "    \n",
        "    target_layers = [model.features[28]]\n",
        "\n",
        "\n",
        "    transform = transforms.Compose([\n",
        "        transforms.Resize((224, 224)), # Correct input size\n",
        "        transforms.ToTensor(),\n",
        "        transforms.Normalize(mean=[0.5, 0.5, 0.5], std=[0.5, 0.5, 0.5])  # Normalize for 1 channel \n",
        "    ])\n",
        "\n",
        "    original_images = []\n",
        "    correct_heatmaps = []\n",
        "    incorrect_heatmaps = []\n",
        "    misclassified_tensors = []\n",
        "    correctly_classified_tensors = []\n",
        "    #prediction_results = []\n",
        "\n",
        "    class_names = [\"Cesarean Birth\", \"Vaginal Birth\"]\n",
        "\n",
        "    for img_name in os.listdir(input_folder):\n",
        "        if not img_name.lower().endswith((\".png\")):\n",
        "            continue\n",
        "\n",
        "        img_path = os.path.join(input_folder, img_name)\n",
        "        image = Image.open(img_path).convert(\"RGB\") \n",
        "\n",
        "        \n",
        "        input_tensor = transform(image).unsqueeze(0).to(device)\n",
        "        # Save the resized image as original (224x224) to ensure overlay consistency\n",
        "        resized_image = transforms.Resize((224, 224))(image)\n",
        "        original_np = np.array(resized_image)\n",
        "        original_images.append(original_np)\n",
        "\n",
        "\n",
        "        # Previsão para obter classe\n",
        "        with torch.no_grad():\n",
        "            output = model(input_tensor)\n",
        "            prediction = output.argmax(dim=1).item()\n",
        "            probabilities = torch.softmax(output, dim=1)\n",
        "            confidence = probabilities[0, prediction].item()\n",
        "\n",
        "        # Grad-CAM\n",
        "        with GradCAM(model=model, target_layers=target_layers) as cam:   #use_cuda=torch.cuda.is_available()\n",
        "            targets = [ClassifierOutputTarget(prediction)]\n",
        "            grayscale_cam = cam(input_tensor=input_tensor, targets=targets)[0]  # [H, W]\n",
        "\n",
        "\n",
        "        # Access raw activations (before interpolation)\n",
        "        raw_activations = cam.activations_and_grads.activations[-1]  # shape: [B, C, H, W]\n",
        "        print(\"RAW FEATURE MAP SHAPE:\", raw_activations.shape)  # For example: torch.Size([1, 1664, 5, 5])\n",
        "\n",
        "        # Just spatial resolution (pre-Grad-CAM aggregation)\n",
        "        h_raw, w_raw = raw_activations.shape[-2:]\n",
        "        print(f\"Raw heatmap resolution: {h_raw}x{w_raw}\")\n",
        "\n",
        "\n",
        "\n",
        "        # === Ground truth from folder name ===\n",
        "        ground_truth_label = get_ground_truth(img_name, input_folder)\n",
        "        ground_truth_class = class_names.index(ground_truth_label)\n",
        "\n",
        "        # Add frame\n",
        "        frame_color = (0, 255, 0)  # green\n",
        "        if prediction != ground_truth_class:\n",
        "            frame_color = (0, 0, 255)  # red\n",
        "\n",
        "        # === Overlay and save ===\n",
        "        overlay = overlay_heatmap(original_np, grayscale_cam[np.newaxis, ...])  # adiciona dimensão extra\n",
        "        overlay_with_frame = add_colored_frame(overlay, frame_color, thickness=7)\n",
        "\n",
        "        # === Save heatmap image ===\n",
        "        save_path = os.path.join(output_folder, f\"heatmap_{class_names[prediction]}_{img_name}\")\n",
        "        cv2.imwrite(save_path, overlay_with_frame)\n",
        "\n",
        "        # === Save heatmap for mean and tensor for grid ===\n",
        "        overlay_rgb = cv2.cvtColor(overlay_with_frame, cv2.COLOR_BGR2RGB) #converts to rgb\n",
        "        overlay_pil = Image.fromarray(overlay_rgb).resize(grid_image_size) # downsizes the image to fit the grid\n",
        "        tensor_for_grid = TF.to_tensor(overlay_pil) #converts into a pytorch tensor [3,H,W] and normalizes pixel values\n",
        "\n",
        "        if prediction == ground_truth_class:\n",
        "            correctly_classified_tensors.append(tensor_for_grid)\n",
        "            correct_heatmaps.append(grayscale_cam)  # 2D spatial heatmap , cam shape = [7,7]\n",
        "        else:\n",
        "            misclassified_tensors.append(tensor_for_grid)\n",
        "            incorrect_heatmaps.append(grayscale_cam)\n",
        "\n",
        "\n",
        "    # === CREATE GRID ===\n",
        "    final_sorted_grid = misclassified_tensors + correctly_classified_tensors\n",
        "    if final_sorted_grid:\n",
        "        grid = vutils.make_grid(final_sorted_grid, nrow=20, padding=5, normalize=True)\n",
        "        grid_path = os.path.join(output_folder, \"grid_overlay_ordered.jpg\")\n",
        "        vutils.save_image(grid, grid_path)\n",
        "        #print(f\"Grid saved at: {grid_path}\")\n",
        "\n",
        "    # === CALCULATE CORRECT MEAN HEATMAP ===\n",
        "    if correct_heatmaps: #list of NumPy arrays (raw grad-cam maps before resizing or coloring), each w\\ shape [3, 3]\n",
        "        mean_heatmap = np.mean(np.stack(correct_heatmaps), axis=0) # turns list of N heatmaps into 3D array w\\ shape [N, 7, 7]\n",
        "        mean_heatmap -= mean_heatmap.min() # subtracts the minimum value from every pixel so the lowest value is 0\n",
        "        mean_heatmap /= (mean_heatmap.max() + 1e-8) # divides every pixel by the new maximum value (normalize) ; adds 1e-8 to ensure it wont be divided by 0\n",
        "        heatmap_uint8 = np.uint8(255 * mean_heatmap) # Converts [0.0 – 1.0] → [0 – 255] format needed for OpenCV\n",
        "        heatmap_colored = cv2.applyColorMap(heatmap_uint8, cv2.COLORMAP_JET) # assigns color to the values\n",
        "\n",
        "        # Resize to match original image size\n",
        "        h, w = original_images[0].shape[:2]\n",
        "        heatmap_resized_blocky = cv2.resize(heatmap_colored, (w, h), interpolation=cv2.INTER_NEAREST) #INTER_CUBIC for smoother transitions ; INTER_NEAREST for blocky look\n",
        "        heatmap_resized_smooth = cv2.resize(heatmap_colored, (w, h), interpolation=cv2.INTER_CUBIC)\n",
        "\n",
        "\n",
        "        mean_path_blocky = os.path.join(output_folder, \"correct_mean_heatmap_blocky.png\")\n",
        "        cv2.imwrite(mean_path_blocky, heatmap_resized_blocky)\n",
        "        #print(f\"Mean heatmap (correct only) saved at: {mean_path_blocky}\")\n",
        "\n",
        "        mean_path_smooth = os.path.join(output_folder, \"correct_mean_smooth.png\")\n",
        "        cv2.imwrite(mean_path_smooth, heatmap_resized_smooth)\n",
        "        #print(f\"Mean heatmap (correct only) saved at: {mean_path_smooth}\")\n",
        "\n",
        "    # === CALCULATE INCORRECT MEAN HEATMAP ===\n",
        "    if incorrect_heatmaps:\n",
        "        mean_heatmap_incorrect = np.mean(np.stack(incorrect_heatmaps), axis=0)\n",
        "        mean_heatmap_incorrect -= mean_heatmap_incorrect.min()\n",
        "        mean_heatmap_incorrect /= (mean_heatmap_incorrect.max() + 1e-8)\n",
        "        heatmap_uint8_incorrect = np.uint8(255 * mean_heatmap_incorrect)\n",
        "        heatmap_colored_incorrect = cv2.applyColorMap(heatmap_uint8_incorrect, cv2.COLORMAP_JET)\n",
        "\n",
        "        h, w = original_images[0].shape[:2]\n",
        "        heatmap_resized_blocky_incorrect = cv2.resize(heatmap_colored_incorrect, (w, h), interpolation=cv2.INTER_NEAREST)\n",
        "        heatmap_resized_smooth_incorrect = cv2.resize(heatmap_colored_incorrect, (w, h), interpolation=cv2.INTER_CUBIC)\n",
        "\n",
        "        mean_path_blocky_incorrect = os.path.join(output_folder, \"incorrect_mean_heatmap_blocky.png\")\n",
        "        cv2.imwrite(mean_path_blocky_incorrect, heatmap_resized_blocky_incorrect)\n",
        "        print(f\"Mean heatmap (incorrect only) saved at: {mean_path_blocky_incorrect}\")\n",
        "\n",
        "        mean_path_smooth_incorrect = os.path.join(output_folder, \"incorrect_mean_smooth.png\")\n",
        "        cv2.imwrite(mean_path_smooth_incorrect, heatmap_resized_smooth_incorrect)\n",
        "        print(f\"Mean heatmap (incorrect only) saved at: {mean_path_smooth_incorrect}\")\n",
        "\n",
        "\n",
        "    return correct_heatmaps, original_images"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 8,
      "metadata": {},
      "outputs": [
        {
          "data": {
            "text/plain": [
              "'def generate_prediction_table_only(model, input_folder, split_name, structure, birth_type, dataset):\\n    transform = transforms.Compose([\\n        transforms.Resize((224, 224)),\\n        transforms.ToTensor(),\\n        transforms.Normalize(mean=[0.5, 0.5, 0.5], std=[0.5, 0.5, 0.5])\\n    ])\\n\\n    class_names = [\"Cesarean Birth\", \"Vaginal Birth\"]\\n    prediction_results = []\\n\\n    for img_name in os.listdir(input_folder):\\n        if not img_name.lower().endswith(\".png\"):\\n            continue\\n\\n        img_path = os.path.join(input_folder, img_name)\\n        image = Image.open(img_path).convert(\"RGB\")\\n        input_tensor = transform(image).unsqueeze(0).to(device)\\n\\n        with torch.no_grad():\\n            output = model(input_tensor)\\n            prediction = output.argmax(dim=1).item()\\n            probabilities = torch.softmax(output, dim=1)\\n            confidence = probabilities[0, prediction].item()\\n\\n        ground_truth_label = get_ground_truth(img_name, input_folder)\\n        ground_truth_class = class_names.index(ground_truth_label)\\n\\n        prediction_results.append({\\n            \"Image\": img_name,\\n            \"Predicted Class\": class_names[prediction],\\n            \"Ground Truth\": ground_truth_label,\\n            \"Correct\": prediction == ground_truth_class,\\n            \"Confidence\": round(confidence, 4),\\n            \"Split\": split_name,\\n            \"Structure\": structure,\\n            \"Birth Type\": birth_type,\\n            \"Dataset\": dataset\\n        })\\n\\n    return pd.DataFrame(prediction_results)'"
            ]
          },
          "execution_count": 8,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "\"\"\"def generate_prediction_table_only(model, input_folder, split_name, structure, birth_type, dataset):\n",
        "    transform = transforms.Compose([\n",
        "        transforms.Resize((224, 224)),\n",
        "        transforms.ToTensor(),\n",
        "        transforms.Normalize(mean=[0.5, 0.5, 0.5], std=[0.5, 0.5, 0.5])\n",
        "    ])\n",
        "\n",
        "    class_names = [\"Cesarean Birth\", \"Vaginal Birth\"]\n",
        "    prediction_results = []\n",
        "\n",
        "    for img_name in os.listdir(input_folder):\n",
        "        if not img_name.lower().endswith(\".png\"):\n",
        "            continue\n",
        "\n",
        "        img_path = os.path.join(input_folder, img_name)\n",
        "        image = Image.open(img_path).convert(\"RGB\")\n",
        "        input_tensor = transform(image).unsqueeze(0).to(device)\n",
        "\n",
        "        with torch.no_grad():\n",
        "            output = model(input_tensor)\n",
        "            prediction = output.argmax(dim=1).item()\n",
        "            probabilities = torch.softmax(output, dim=1)\n",
        "            confidence = probabilities[0, prediction].item()\n",
        "\n",
        "        ground_truth_label = get_ground_truth(img_name, input_folder)\n",
        "        ground_truth_class = class_names.index(ground_truth_label)\n",
        "\n",
        "        prediction_results.append({\n",
        "            \"Image\": img_name,\n",
        "            \"Predicted Class\": class_names[prediction],\n",
        "            \"Ground Truth\": ground_truth_label,\n",
        "            \"Correct\": prediction == ground_truth_class,\n",
        "            \"Confidence\": round(confidence, 4),\n",
        "            \"Split\": split_name,\n",
        "            \"Structure\": structure,\n",
        "            \"Birth Type\": birth_type,\n",
        "            \"Dataset\": dataset\n",
        "        })\n",
        "\n",
        "    return pd.DataFrame(prediction_results)\"\"\""
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 9,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Processing: Abdomen_, Cesarean Birth, test, cv3\n",
            "initialize_weights...\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "C:\\Users\\anale\\AppData\\Local\\Temp\\ipykernel_10220\\2053349774.py:7: FutureWarning: You are using `torch.load` with `weights_only=False` (the current default value), which uses the default pickle module implicitly. It is possible to construct malicious pickle data which will execute arbitrary code during unpickling (See https://github.com/pytorch/pytorch/blob/main/SECURITY.md#untrusted-models for more details). In a future release, the default value for `weights_only` will be flipped to `True`. This limits the functions that could be executed during unpickling. Arbitrary objects will no longer be allowed to be loaded via this mode unless they are explicitly allowlisted by the user via `torch.serialization.add_safe_globals`. We recommend you start setting `weights_only=True` for any use case where you don't have full control of the loaded file. Please open an issue on GitHub for any issues related to this experimental feature.\n",
            "  state_dict = torch.load(weight_path, map_location=device)\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Sequential(\n",
            "  (0): ECB(\n",
            "    (patch_embed): PatchEmbed(\n",
            "      (avgpool): Identity()\n",
            "      (conv): Conv2d(64, 96, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
            "      (norm): BatchNorm2d(96, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "    )\n",
            "    (mhca): MHCA(\n",
            "      (group_conv3x3): Conv2d(96, 96, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=3, bias=False)\n",
            "      (norm): BatchNorm2d(96, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "      (act): ReLU(inplace=True)\n",
            "      (projection): Conv2d(96, 96, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
            "    )\n",
            "    (attention_path_dropout): DropPath(drop_prob=0.000)\n",
            "    (conv): LocalityFeedForward(\n",
            "      (conv): Sequential(\n",
            "        (0): Conv2d(96, 288, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
            "        (1): BatchNorm2d(288, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "        (2): h_swish(\n",
            "          (sigmoid): h_sigmoid(\n",
            "            (relu): ReLU6(inplace=True)\n",
            "          )\n",
            "        )\n",
            "        (3): Conv2d(288, 288, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=288, bias=False)\n",
            "        (4): BatchNorm2d(288, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "        (5): h_swish(\n",
            "          (sigmoid): h_sigmoid(\n",
            "            (relu): ReLU6(inplace=True)\n",
            "          )\n",
            "        )\n",
            "        (6): SELayer(\n",
            "          (avg_pool): AdaptiveAvgPool2d(output_size=1)\n",
            "          (fc): Sequential(\n",
            "            (0): Linear(in_features=288, out_features=3, bias=True)\n",
            "            (1): ReLU(inplace=True)\n",
            "            (2): Linear(in_features=3, out_features=288, bias=True)\n",
            "            (3): h_sigmoid(\n",
            "              (relu): ReLU6(inplace=True)\n",
            "            )\n",
            "          )\n",
            "        )\n",
            "        (7): Conv2d(288, 96, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
            "        (8): BatchNorm2d(96, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "      )\n",
            "    )\n",
            "    (norm): BatchNorm2d(96, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "  )\n",
            "  (1): ECB(\n",
            "    (patch_embed): PatchEmbed(\n",
            "      (avgpool): Identity()\n",
            "      (conv): Identity()\n",
            "      (norm): Identity()\n",
            "    )\n",
            "    (mhca): MHCA(\n",
            "      (group_conv3x3): Conv2d(96, 96, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=3, bias=False)\n",
            "      (norm): BatchNorm2d(96, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "      (act): ReLU(inplace=True)\n",
            "      (projection): Conv2d(96, 96, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
            "    )\n",
            "    (attention_path_dropout): DropPath(drop_prob=0.007)\n",
            "    (conv): LocalityFeedForward(\n",
            "      (conv): Sequential(\n",
            "        (0): Conv2d(96, 288, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
            "        (1): BatchNorm2d(288, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "        (2): h_swish(\n",
            "          (sigmoid): h_sigmoid(\n",
            "            (relu): ReLU6(inplace=True)\n",
            "          )\n",
            "        )\n",
            "        (3): Conv2d(288, 288, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=288, bias=False)\n",
            "        (4): BatchNorm2d(288, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "        (5): h_swish(\n",
            "          (sigmoid): h_sigmoid(\n",
            "            (relu): ReLU6(inplace=True)\n",
            "          )\n",
            "        )\n",
            "        (6): SELayer(\n",
            "          (avg_pool): AdaptiveAvgPool2d(output_size=1)\n",
            "          (fc): Sequential(\n",
            "            (0): Linear(in_features=288, out_features=3, bias=True)\n",
            "            (1): ReLU(inplace=True)\n",
            "            (2): Linear(in_features=3, out_features=288, bias=True)\n",
            "            (3): h_sigmoid(\n",
            "              (relu): ReLU6(inplace=True)\n",
            "            )\n",
            "          )\n",
            "        )\n",
            "        (7): Conv2d(288, 96, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
            "        (8): BatchNorm2d(96, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "      )\n",
            "    )\n",
            "    (norm): BatchNorm2d(96, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "  )\n",
            "  (2): ECB(\n",
            "    (patch_embed): PatchEmbed(\n",
            "      (avgpool): Identity()\n",
            "      (conv): Identity()\n",
            "      (norm): Identity()\n",
            "    )\n",
            "    (mhca): MHCA(\n",
            "      (group_conv3x3): Conv2d(96, 96, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=3, bias=False)\n",
            "      (norm): BatchNorm2d(96, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "      (act): ReLU(inplace=True)\n",
            "      (projection): Conv2d(96, 96, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
            "    )\n",
            "    (attention_path_dropout): DropPath(drop_prob=0.014)\n",
            "    (conv): LocalityFeedForward(\n",
            "      (conv): Sequential(\n",
            "        (0): Conv2d(96, 288, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
            "        (1): BatchNorm2d(288, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "        (2): h_swish(\n",
            "          (sigmoid): h_sigmoid(\n",
            "            (relu): ReLU6(inplace=True)\n",
            "          )\n",
            "        )\n",
            "        (3): Conv2d(288, 288, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=288, bias=False)\n",
            "        (4): BatchNorm2d(288, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "        (5): h_swish(\n",
            "          (sigmoid): h_sigmoid(\n",
            "            (relu): ReLU6(inplace=True)\n",
            "          )\n",
            "        )\n",
            "        (6): SELayer(\n",
            "          (avg_pool): AdaptiveAvgPool2d(output_size=1)\n",
            "          (fc): Sequential(\n",
            "            (0): Linear(in_features=288, out_features=3, bias=True)\n",
            "            (1): ReLU(inplace=True)\n",
            "            (2): Linear(in_features=3, out_features=288, bias=True)\n",
            "            (3): h_sigmoid(\n",
            "              (relu): ReLU6(inplace=True)\n",
            "            )\n",
            "          )\n",
            "        )\n",
            "        (7): Conv2d(288, 96, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
            "        (8): BatchNorm2d(96, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "      )\n",
            "    )\n",
            "    (norm): BatchNorm2d(96, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "  )\n",
            "  (3): ECB(\n",
            "    (patch_embed): PatchEmbed(\n",
            "      (avgpool): AvgPool2d(kernel_size=(2, 2), stride=2, padding=0)\n",
            "      (conv): Conv2d(96, 192, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
            "      (norm): BatchNorm2d(192, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "    )\n",
            "    (mhca): MHCA(\n",
            "      (group_conv3x3): Conv2d(192, 192, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=6, bias=False)\n",
            "      (norm): BatchNorm2d(192, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "      (act): ReLU(inplace=True)\n",
            "      (projection): Conv2d(192, 192, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
            "    )\n",
            "    (attention_path_dropout): DropPath(drop_prob=0.021)\n",
            "    (conv): LocalityFeedForward(\n",
            "      (conv): Sequential(\n",
            "        (0): Conv2d(192, 576, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
            "        (1): BatchNorm2d(576, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "        (2): h_swish(\n",
            "          (sigmoid): h_sigmoid(\n",
            "            (relu): ReLU6(inplace=True)\n",
            "          )\n",
            "        )\n",
            "        (3): Conv2d(576, 576, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=576, bias=False)\n",
            "        (4): BatchNorm2d(576, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "        (5): h_swish(\n",
            "          (sigmoid): h_sigmoid(\n",
            "            (relu): ReLU6(inplace=True)\n",
            "          )\n",
            "        )\n",
            "        (6): SELayer(\n",
            "          (avg_pool): AdaptiveAvgPool2d(output_size=1)\n",
            "          (fc): Sequential(\n",
            "            (0): Linear(in_features=576, out_features=3, bias=True)\n",
            "            (1): ReLU(inplace=True)\n",
            "            (2): Linear(in_features=3, out_features=576, bias=True)\n",
            "            (3): h_sigmoid(\n",
            "              (relu): ReLU6(inplace=True)\n",
            "            )\n",
            "          )\n",
            "        )\n",
            "        (7): Conv2d(576, 192, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
            "        (8): BatchNorm2d(192, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "      )\n",
            "    )\n",
            "    (norm): BatchNorm2d(192, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "  )\n",
            "  (4): ECB(\n",
            "    (patch_embed): PatchEmbed(\n",
            "      (avgpool): Identity()\n",
            "      (conv): Identity()\n",
            "      (norm): Identity()\n",
            "    )\n",
            "    (mhca): MHCA(\n",
            "      (group_conv3x3): Conv2d(192, 192, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=6, bias=False)\n",
            "      (norm): BatchNorm2d(192, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "      (act): ReLU(inplace=True)\n",
            "      (projection): Conv2d(192, 192, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
            "    )\n",
            "    (attention_path_dropout): DropPath(drop_prob=0.028)\n",
            "    (conv): LocalityFeedForward(\n",
            "      (conv): Sequential(\n",
            "        (0): Conv2d(192, 576, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
            "        (1): BatchNorm2d(576, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "        (2): h_swish(\n",
            "          (sigmoid): h_sigmoid(\n",
            "            (relu): ReLU6(inplace=True)\n",
            "          )\n",
            "        )\n",
            "        (3): Conv2d(576, 576, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=576, bias=False)\n",
            "        (4): BatchNorm2d(576, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "        (5): h_swish(\n",
            "          (sigmoid): h_sigmoid(\n",
            "            (relu): ReLU6(inplace=True)\n",
            "          )\n",
            "        )\n",
            "        (6): SELayer(\n",
            "          (avg_pool): AdaptiveAvgPool2d(output_size=1)\n",
            "          (fc): Sequential(\n",
            "            (0): Linear(in_features=576, out_features=3, bias=True)\n",
            "            (1): ReLU(inplace=True)\n",
            "            (2): Linear(in_features=3, out_features=576, bias=True)\n",
            "            (3): h_sigmoid(\n",
            "              (relu): ReLU6(inplace=True)\n",
            "            )\n",
            "          )\n",
            "        )\n",
            "        (7): Conv2d(576, 192, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
            "        (8): BatchNorm2d(192, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "      )\n",
            "    )\n",
            "    (norm): BatchNorm2d(192, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "  )\n",
            "  (5): ECB(\n",
            "    (patch_embed): PatchEmbed(\n",
            "      (avgpool): Identity()\n",
            "      (conv): Identity()\n",
            "      (norm): Identity()\n",
            "    )\n",
            "    (mhca): MHCA(\n",
            "      (group_conv3x3): Conv2d(192, 192, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=6, bias=False)\n",
            "      (norm): BatchNorm2d(192, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "      (act): ReLU(inplace=True)\n",
            "      (projection): Conv2d(192, 192, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
            "    )\n",
            "    (attention_path_dropout): DropPath(drop_prob=0.034)\n",
            "    (conv): LocalityFeedForward(\n",
            "      (conv): Sequential(\n",
            "        (0): Conv2d(192, 576, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
            "        (1): BatchNorm2d(576, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "        (2): h_swish(\n",
            "          (sigmoid): h_sigmoid(\n",
            "            (relu): ReLU6(inplace=True)\n",
            "          )\n",
            "        )\n",
            "        (3): Conv2d(576, 576, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=576, bias=False)\n",
            "        (4): BatchNorm2d(576, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "        (5): h_swish(\n",
            "          (sigmoid): h_sigmoid(\n",
            "            (relu): ReLU6(inplace=True)\n",
            "          )\n",
            "        )\n",
            "        (6): SELayer(\n",
            "          (avg_pool): AdaptiveAvgPool2d(output_size=1)\n",
            "          (fc): Sequential(\n",
            "            (0): Linear(in_features=576, out_features=3, bias=True)\n",
            "            (1): ReLU(inplace=True)\n",
            "            (2): Linear(in_features=3, out_features=576, bias=True)\n",
            "            (3): h_sigmoid(\n",
            "              (relu): ReLU6(inplace=True)\n",
            "            )\n",
            "          )\n",
            "        )\n",
            "        (7): Conv2d(576, 192, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
            "        (8): BatchNorm2d(192, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "      )\n",
            "    )\n",
            "    (norm): BatchNorm2d(192, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "  )\n",
            "  (6): LTB(\n",
            "    (patch_embed): PatchEmbed(\n",
            "      (avgpool): Identity()\n",
            "      (conv): Identity()\n",
            "      (norm): Identity()\n",
            "    )\n",
            "    (norm1): BatchNorm2d(192, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "    (e_mhsa): E_MHSA(\n",
            "      (q): Linear(in_features=192, out_features=192, bias=True)\n",
            "      (k): Linear(in_features=192, out_features=192, bias=True)\n",
            "      (v): Linear(in_features=192, out_features=192, bias=True)\n",
            "      (proj): Linear(in_features=192, out_features=192, bias=True)\n",
            "      (attn_drop): Dropout(p=0, inplace=False)\n",
            "      (proj_drop): Dropout(p=0, inplace=False)\n",
            "      (sr): AvgPool1d(kernel_size=(16,), stride=(16,), padding=(0,))\n",
            "      (norm): BatchNorm1d(192, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "    )\n",
            "    (mhsa_path_dropout): DropPath(drop_prob=0.031)\n",
            "    (projection): PatchEmbed(\n",
            "      (avgpool): Identity()\n",
            "      (conv): Conv2d(192, 64, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
            "      (norm): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "    )\n",
            "    (mhca): MHCA(\n",
            "      (group_conv3x3): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=2, bias=False)\n",
            "      (norm): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "      (act): ReLU(inplace=True)\n",
            "      (projection): Conv2d(64, 64, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
            "    )\n",
            "    (mhca_path_dropout): DropPath(drop_prob=0.010)\n",
            "    (norm2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "    (conv): LocalityFeedForward(\n",
            "      (conv): Sequential(\n",
            "        (0): Conv2d(256, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
            "        (1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "        (2): h_swish(\n",
            "          (sigmoid): h_sigmoid(\n",
            "            (relu): ReLU6(inplace=True)\n",
            "          )\n",
            "        )\n",
            "        (3): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=512, bias=False)\n",
            "        (4): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "        (5): h_swish(\n",
            "          (sigmoid): h_sigmoid(\n",
            "            (relu): ReLU6(inplace=True)\n",
            "          )\n",
            "        )\n",
            "        (6): SELayer(\n",
            "          (avg_pool): AdaptiveAvgPool2d(output_size=1)\n",
            "          (fc): Sequential(\n",
            "            (0): Linear(in_features=512, out_features=2, bias=True)\n",
            "            (1): ReLU(inplace=True)\n",
            "            (2): Linear(in_features=2, out_features=512, bias=True)\n",
            "            (3): h_sigmoid(\n",
            "              (relu): ReLU6(inplace=True)\n",
            "            )\n",
            "          )\n",
            "        )\n",
            "        (7): Conv2d(512, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
            "        (8): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "      )\n",
            "    )\n",
            "  )\n",
            "  (7): ECB(\n",
            "    (patch_embed): PatchEmbed(\n",
            "      (avgpool): AvgPool2d(kernel_size=(2, 2), stride=2, padding=0)\n",
            "      (conv): Conv2d(256, 384, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
            "      (norm): BatchNorm2d(384, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "    )\n",
            "    (mhca): MHCA(\n",
            "      (group_conv3x3): Conv2d(384, 384, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=12, bias=False)\n",
            "      (norm): BatchNorm2d(384, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "      (act): ReLU(inplace=True)\n",
            "      (projection): Conv2d(384, 384, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
            "    )\n",
            "    (attention_path_dropout): DropPath(drop_prob=0.048)\n",
            "    (conv): LocalityFeedForward(\n",
            "      (conv): Sequential(\n",
            "        (0): Conv2d(384, 1152, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
            "        (1): BatchNorm2d(1152, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "        (2): h_swish(\n",
            "          (sigmoid): h_sigmoid(\n",
            "            (relu): ReLU6(inplace=True)\n",
            "          )\n",
            "        )\n",
            "        (3): Conv2d(1152, 1152, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=1152, bias=False)\n",
            "        (4): BatchNorm2d(1152, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "        (5): h_swish(\n",
            "          (sigmoid): h_sigmoid(\n",
            "            (relu): ReLU6(inplace=True)\n",
            "          )\n",
            "        )\n",
            "        (6): SELayer(\n",
            "          (avg_pool): AdaptiveAvgPool2d(output_size=1)\n",
            "          (fc): Sequential(\n",
            "            (0): Linear(in_features=1152, out_features=3, bias=True)\n",
            "            (1): ReLU(inplace=True)\n",
            "            (2): Linear(in_features=3, out_features=1152, bias=True)\n",
            "            (3): h_sigmoid(\n",
            "              (relu): ReLU6(inplace=True)\n",
            "            )\n",
            "          )\n",
            "        )\n",
            "        (7): Conv2d(1152, 384, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
            "        (8): BatchNorm2d(384, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "      )\n",
            "    )\n",
            "    (norm): BatchNorm2d(384, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "  )\n",
            "  (8): ECB(\n",
            "    (patch_embed): PatchEmbed(\n",
            "      (avgpool): Identity()\n",
            "      (conv): Identity()\n",
            "      (norm): Identity()\n",
            "    )\n",
            "    (mhca): MHCA(\n",
            "      (group_conv3x3): Conv2d(384, 384, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=12, bias=False)\n",
            "      (norm): BatchNorm2d(384, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "      (act): ReLU(inplace=True)\n",
            "      (projection): Conv2d(384, 384, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
            "    )\n",
            "    (attention_path_dropout): DropPath(drop_prob=0.055)\n",
            "    (conv): LocalityFeedForward(\n",
            "      (conv): Sequential(\n",
            "        (0): Conv2d(384, 1152, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
            "        (1): BatchNorm2d(1152, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "        (2): h_swish(\n",
            "          (sigmoid): h_sigmoid(\n",
            "            (relu): ReLU6(inplace=True)\n",
            "          )\n",
            "        )\n",
            "        (3): Conv2d(1152, 1152, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=1152, bias=False)\n",
            "        (4): BatchNorm2d(1152, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "        (5): h_swish(\n",
            "          (sigmoid): h_sigmoid(\n",
            "            (relu): ReLU6(inplace=True)\n",
            "          )\n",
            "        )\n",
            "        (6): SELayer(\n",
            "          (avg_pool): AdaptiveAvgPool2d(output_size=1)\n",
            "          (fc): Sequential(\n",
            "            (0): Linear(in_features=1152, out_features=3, bias=True)\n",
            "            (1): ReLU(inplace=True)\n",
            "            (2): Linear(in_features=3, out_features=1152, bias=True)\n",
            "            (3): h_sigmoid(\n",
            "              (relu): ReLU6(inplace=True)\n",
            "            )\n",
            "          )\n",
            "        )\n",
            "        (7): Conv2d(1152, 384, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
            "        (8): BatchNorm2d(384, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "      )\n",
            "    )\n",
            "    (norm): BatchNorm2d(384, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "  )\n",
            "  (9): ECB(\n",
            "    (patch_embed): PatchEmbed(\n",
            "      (avgpool): Identity()\n",
            "      (conv): Identity()\n",
            "      (norm): Identity()\n",
            "    )\n",
            "    (mhca): MHCA(\n",
            "      (group_conv3x3): Conv2d(384, 384, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=12, bias=False)\n",
            "      (norm): BatchNorm2d(384, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "      (act): ReLU(inplace=True)\n",
            "      (projection): Conv2d(384, 384, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
            "    )\n",
            "    (attention_path_dropout): DropPath(drop_prob=0.062)\n",
            "    (conv): LocalityFeedForward(\n",
            "      (conv): Sequential(\n",
            "        (0): Conv2d(384, 1152, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
            "        (1): BatchNorm2d(1152, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "        (2): h_swish(\n",
            "          (sigmoid): h_sigmoid(\n",
            "            (relu): ReLU6(inplace=True)\n",
            "          )\n",
            "        )\n",
            "        (3): Conv2d(1152, 1152, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=1152, bias=False)\n",
            "        (4): BatchNorm2d(1152, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "        (5): h_swish(\n",
            "          (sigmoid): h_sigmoid(\n",
            "            (relu): ReLU6(inplace=True)\n",
            "          )\n",
            "        )\n",
            "        (6): SELayer(\n",
            "          (avg_pool): AdaptiveAvgPool2d(output_size=1)\n",
            "          (fc): Sequential(\n",
            "            (0): Linear(in_features=1152, out_features=3, bias=True)\n",
            "            (1): ReLU(inplace=True)\n",
            "            (2): Linear(in_features=3, out_features=1152, bias=True)\n",
            "            (3): h_sigmoid(\n",
            "              (relu): ReLU6(inplace=True)\n",
            "            )\n",
            "          )\n",
            "        )\n",
            "        (7): Conv2d(1152, 384, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
            "        (8): BatchNorm2d(384, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "      )\n",
            "    )\n",
            "    (norm): BatchNorm2d(384, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "  )\n",
            "  (10): ECB(\n",
            "    (patch_embed): PatchEmbed(\n",
            "      (avgpool): Identity()\n",
            "      (conv): Identity()\n",
            "      (norm): Identity()\n",
            "    )\n",
            "    (mhca): MHCA(\n",
            "      (group_conv3x3): Conv2d(384, 384, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=12, bias=False)\n",
            "      (norm): BatchNorm2d(384, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "      (act): ReLU(inplace=True)\n",
            "      (projection): Conv2d(384, 384, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
            "    )\n",
            "    (attention_path_dropout): DropPath(drop_prob=0.069)\n",
            "    (conv): LocalityFeedForward(\n",
            "      (conv): Sequential(\n",
            "        (0): Conv2d(384, 1152, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
            "        (1): BatchNorm2d(1152, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "        (2): h_swish(\n",
            "          (sigmoid): h_sigmoid(\n",
            "            (relu): ReLU6(inplace=True)\n",
            "          )\n",
            "        )\n",
            "        (3): Conv2d(1152, 1152, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=1152, bias=False)\n",
            "        (4): BatchNorm2d(1152, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "        (5): h_swish(\n",
            "          (sigmoid): h_sigmoid(\n",
            "            (relu): ReLU6(inplace=True)\n",
            "          )\n",
            "        )\n",
            "        (6): SELayer(\n",
            "          (avg_pool): AdaptiveAvgPool2d(output_size=1)\n",
            "          (fc): Sequential(\n",
            "            (0): Linear(in_features=1152, out_features=3, bias=True)\n",
            "            (1): ReLU(inplace=True)\n",
            "            (2): Linear(in_features=3, out_features=1152, bias=True)\n",
            "            (3): h_sigmoid(\n",
            "              (relu): ReLU6(inplace=True)\n",
            "            )\n",
            "          )\n",
            "        )\n",
            "        (7): Conv2d(1152, 384, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
            "        (8): BatchNorm2d(384, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "      )\n",
            "    )\n",
            "    (norm): BatchNorm2d(384, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "  )\n",
            "  (11): LTB(\n",
            "    (patch_embed): PatchEmbed(\n",
            "      (avgpool): Identity()\n",
            "      (conv): Identity()\n",
            "      (norm): Identity()\n",
            "    )\n",
            "    (norm1): BatchNorm2d(384, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "    (e_mhsa): E_MHSA(\n",
            "      (q): Linear(in_features=384, out_features=384, bias=True)\n",
            "      (k): Linear(in_features=384, out_features=384, bias=True)\n",
            "      (v): Linear(in_features=384, out_features=384, bias=True)\n",
            "      (proj): Linear(in_features=384, out_features=384, bias=True)\n",
            "      (attn_drop): Dropout(p=0, inplace=False)\n",
            "      (proj_drop): Dropout(p=0, inplace=False)\n",
            "      (sr): AvgPool1d(kernel_size=(4,), stride=(4,), padding=(0,))\n",
            "      (norm): BatchNorm1d(384, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "    )\n",
            "    (mhsa_path_dropout): DropPath(drop_prob=0.057)\n",
            "    (projection): PatchEmbed(\n",
            "      (avgpool): Identity()\n",
            "      (conv): Conv2d(384, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
            "      (norm): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "    )\n",
            "    (mhca): MHCA(\n",
            "      (group_conv3x3): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=4, bias=False)\n",
            "      (norm): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "      (act): ReLU(inplace=True)\n",
            "      (projection): Conv2d(128, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
            "    )\n",
            "    (mhca_path_dropout): DropPath(drop_prob=0.019)\n",
            "    (norm2): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "    (conv): LocalityFeedForward(\n",
            "      (conv): Sequential(\n",
            "        (0): Conv2d(512, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
            "        (1): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "        (2): h_swish(\n",
            "          (sigmoid): h_sigmoid(\n",
            "            (relu): ReLU6(inplace=True)\n",
            "          )\n",
            "        )\n",
            "        (3): Conv2d(1024, 1024, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=1024, bias=False)\n",
            "        (4): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "        (5): h_swish(\n",
            "          (sigmoid): h_sigmoid(\n",
            "            (relu): ReLU6(inplace=True)\n",
            "          )\n",
            "        )\n",
            "        (6): SELayer(\n",
            "          (avg_pool): AdaptiveAvgPool2d(output_size=1)\n",
            "          (fc): Sequential(\n",
            "            (0): Linear(in_features=1024, out_features=2, bias=True)\n",
            "            (1): ReLU(inplace=True)\n",
            "            (2): Linear(in_features=2, out_features=1024, bias=True)\n",
            "            (3): h_sigmoid(\n",
            "              (relu): ReLU6(inplace=True)\n",
            "            )\n",
            "          )\n",
            "        )\n",
            "        (7): Conv2d(1024, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
            "        (8): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "      )\n",
            "    )\n",
            "  )\n",
            "  (12): ECB(\n",
            "    (patch_embed): PatchEmbed(\n",
            "      (avgpool): Identity()\n",
            "      (conv): Conv2d(512, 384, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
            "      (norm): BatchNorm2d(384, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "    )\n",
            "    (mhca): MHCA(\n",
            "      (group_conv3x3): Conv2d(384, 384, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=12, bias=False)\n",
            "      (norm): BatchNorm2d(384, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "      (act): ReLU(inplace=True)\n",
            "      (projection): Conv2d(384, 384, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
            "    )\n",
            "    (attention_path_dropout): DropPath(drop_prob=0.083)\n",
            "    (conv): LocalityFeedForward(\n",
            "      (conv): Sequential(\n",
            "        (0): Conv2d(384, 1152, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
            "        (1): BatchNorm2d(1152, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "        (2): h_swish(\n",
            "          (sigmoid): h_sigmoid(\n",
            "            (relu): ReLU6(inplace=True)\n",
            "          )\n",
            "        )\n",
            "        (3): Conv2d(1152, 1152, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=1152, bias=False)\n",
            "        (4): BatchNorm2d(1152, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "        (5): h_swish(\n",
            "          (sigmoid): h_sigmoid(\n",
            "            (relu): ReLU6(inplace=True)\n",
            "          )\n",
            "        )\n",
            "        (6): SELayer(\n",
            "          (avg_pool): AdaptiveAvgPool2d(output_size=1)\n",
            "          (fc): Sequential(\n",
            "            (0): Linear(in_features=1152, out_features=3, bias=True)\n",
            "            (1): ReLU(inplace=True)\n",
            "            (2): Linear(in_features=3, out_features=1152, bias=True)\n",
            "            (3): h_sigmoid(\n",
            "              (relu): ReLU6(inplace=True)\n",
            "            )\n",
            "          )\n",
            "        )\n",
            "        (7): Conv2d(1152, 384, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
            "        (8): BatchNorm2d(384, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "      )\n",
            "    )\n",
            "    (norm): BatchNorm2d(384, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "  )\n",
            "  (13): ECB(\n",
            "    (patch_embed): PatchEmbed(\n",
            "      (avgpool): Identity()\n",
            "      (conv): Identity()\n",
            "      (norm): Identity()\n",
            "    )\n",
            "    (mhca): MHCA(\n",
            "      (group_conv3x3): Conv2d(384, 384, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=12, bias=False)\n",
            "      (norm): BatchNorm2d(384, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "      (act): ReLU(inplace=True)\n",
            "      (projection): Conv2d(384, 384, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
            "    )\n",
            "    (attention_path_dropout): DropPath(drop_prob=0.090)\n",
            "    (conv): LocalityFeedForward(\n",
            "      (conv): Sequential(\n",
            "        (0): Conv2d(384, 1152, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
            "        (1): BatchNorm2d(1152, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "        (2): h_swish(\n",
            "          (sigmoid): h_sigmoid(\n",
            "            (relu): ReLU6(inplace=True)\n",
            "          )\n",
            "        )\n",
            "        (3): Conv2d(1152, 1152, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=1152, bias=False)\n",
            "        (4): BatchNorm2d(1152, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "        (5): h_swish(\n",
            "          (sigmoid): h_sigmoid(\n",
            "            (relu): ReLU6(inplace=True)\n",
            "          )\n",
            "        )\n",
            "        (6): SELayer(\n",
            "          (avg_pool): AdaptiveAvgPool2d(output_size=1)\n",
            "          (fc): Sequential(\n",
            "            (0): Linear(in_features=1152, out_features=3, bias=True)\n",
            "            (1): ReLU(inplace=True)\n",
            "            (2): Linear(in_features=3, out_features=1152, bias=True)\n",
            "            (3): h_sigmoid(\n",
            "              (relu): ReLU6(inplace=True)\n",
            "            )\n",
            "          )\n",
            "        )\n",
            "        (7): Conv2d(1152, 384, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
            "        (8): BatchNorm2d(384, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "      )\n",
            "    )\n",
            "    (norm): BatchNorm2d(384, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "  )\n",
            "  (14): ECB(\n",
            "    (patch_embed): PatchEmbed(\n",
            "      (avgpool): Identity()\n",
            "      (conv): Identity()\n",
            "      (norm): Identity()\n",
            "    )\n",
            "    (mhca): MHCA(\n",
            "      (group_conv3x3): Conv2d(384, 384, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=12, bias=False)\n",
            "      (norm): BatchNorm2d(384, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "      (act): ReLU(inplace=True)\n",
            "      (projection): Conv2d(384, 384, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
            "    )\n",
            "    (attention_path_dropout): DropPath(drop_prob=0.097)\n",
            "    (conv): LocalityFeedForward(\n",
            "      (conv): Sequential(\n",
            "        (0): Conv2d(384, 1152, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
            "        (1): BatchNorm2d(1152, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "        (2): h_swish(\n",
            "          (sigmoid): h_sigmoid(\n",
            "            (relu): ReLU6(inplace=True)\n",
            "          )\n",
            "        )\n",
            "        (3): Conv2d(1152, 1152, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=1152, bias=False)\n",
            "        (4): BatchNorm2d(1152, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "        (5): h_swish(\n",
            "          (sigmoid): h_sigmoid(\n",
            "            (relu): ReLU6(inplace=True)\n",
            "          )\n",
            "        )\n",
            "        (6): SELayer(\n",
            "          (avg_pool): AdaptiveAvgPool2d(output_size=1)\n",
            "          (fc): Sequential(\n",
            "            (0): Linear(in_features=1152, out_features=3, bias=True)\n",
            "            (1): ReLU(inplace=True)\n",
            "            (2): Linear(in_features=3, out_features=1152, bias=True)\n",
            "            (3): h_sigmoid(\n",
            "              (relu): ReLU6(inplace=True)\n",
            "            )\n",
            "          )\n",
            "        )\n",
            "        (7): Conv2d(1152, 384, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
            "        (8): BatchNorm2d(384, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "      )\n",
            "    )\n",
            "    (norm): BatchNorm2d(384, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "  )\n",
            "  (15): ECB(\n",
            "    (patch_embed): PatchEmbed(\n",
            "      (avgpool): Identity()\n",
            "      (conv): Identity()\n",
            "      (norm): Identity()\n",
            "    )\n",
            "    (mhca): MHCA(\n",
            "      (group_conv3x3): Conv2d(384, 384, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=12, bias=False)\n",
            "      (norm): BatchNorm2d(384, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "      (act): ReLU(inplace=True)\n",
            "      (projection): Conv2d(384, 384, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
            "    )\n",
            "    (attention_path_dropout): DropPath(drop_prob=0.103)\n",
            "    (conv): LocalityFeedForward(\n",
            "      (conv): Sequential(\n",
            "        (0): Conv2d(384, 1152, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
            "        (1): BatchNorm2d(1152, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "        (2): h_swish(\n",
            "          (sigmoid): h_sigmoid(\n",
            "            (relu): ReLU6(inplace=True)\n",
            "          )\n",
            "        )\n",
            "        (3): Conv2d(1152, 1152, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=1152, bias=False)\n",
            "        (4): BatchNorm2d(1152, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "        (5): h_swish(\n",
            "          (sigmoid): h_sigmoid(\n",
            "            (relu): ReLU6(inplace=True)\n",
            "          )\n",
            "        )\n",
            "        (6): SELayer(\n",
            "          (avg_pool): AdaptiveAvgPool2d(output_size=1)\n",
            "          (fc): Sequential(\n",
            "            (0): Linear(in_features=1152, out_features=3, bias=True)\n",
            "            (1): ReLU(inplace=True)\n",
            "            (2): Linear(in_features=3, out_features=1152, bias=True)\n",
            "            (3): h_sigmoid(\n",
            "              (relu): ReLU6(inplace=True)\n",
            "            )\n",
            "          )\n",
            "        )\n",
            "        (7): Conv2d(1152, 384, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
            "        (8): BatchNorm2d(384, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "      )\n",
            "    )\n",
            "    (norm): BatchNorm2d(384, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "  )\n",
            "  (16): LTB(\n",
            "    (patch_embed): PatchEmbed(\n",
            "      (avgpool): Identity()\n",
            "      (conv): Identity()\n",
            "      (norm): Identity()\n",
            "    )\n",
            "    (norm1): BatchNorm2d(384, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "    (e_mhsa): E_MHSA(\n",
            "      (q): Linear(in_features=384, out_features=384, bias=True)\n",
            "      (k): Linear(in_features=384, out_features=384, bias=True)\n",
            "      (v): Linear(in_features=384, out_features=384, bias=True)\n",
            "      (proj): Linear(in_features=384, out_features=384, bias=True)\n",
            "      (attn_drop): Dropout(p=0, inplace=False)\n",
            "      (proj_drop): Dropout(p=0, inplace=False)\n",
            "      (sr): AvgPool1d(kernel_size=(4,), stride=(4,), padding=(0,))\n",
            "      (norm): BatchNorm1d(384, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "    )\n",
            "    (mhsa_path_dropout): DropPath(drop_prob=0.083)\n",
            "    (projection): PatchEmbed(\n",
            "      (avgpool): Identity()\n",
            "      (conv): Conv2d(384, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
            "      (norm): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "    )\n",
            "    (mhca): MHCA(\n",
            "      (group_conv3x3): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=4, bias=False)\n",
            "      (norm): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "      (act): ReLU(inplace=True)\n",
            "      (projection): Conv2d(128, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
            "    )\n",
            "    (mhca_path_dropout): DropPath(drop_prob=0.028)\n",
            "    (norm2): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "    (conv): LocalityFeedForward(\n",
            "      (conv): Sequential(\n",
            "        (0): Conv2d(512, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
            "        (1): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "        (2): h_swish(\n",
            "          (sigmoid): h_sigmoid(\n",
            "            (relu): ReLU6(inplace=True)\n",
            "          )\n",
            "        )\n",
            "        (3): Conv2d(1024, 1024, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=1024, bias=False)\n",
            "        (4): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "        (5): h_swish(\n",
            "          (sigmoid): h_sigmoid(\n",
            "            (relu): ReLU6(inplace=True)\n",
            "          )\n",
            "        )\n",
            "        (6): SELayer(\n",
            "          (avg_pool): AdaptiveAvgPool2d(output_size=1)\n",
            "          (fc): Sequential(\n",
            "            (0): Linear(in_features=1024, out_features=2, bias=True)\n",
            "            (1): ReLU(inplace=True)\n",
            "            (2): Linear(in_features=2, out_features=1024, bias=True)\n",
            "            (3): h_sigmoid(\n",
            "              (relu): ReLU6(inplace=True)\n",
            "            )\n",
            "          )\n",
            "        )\n",
            "        (7): Conv2d(1024, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
            "        (8): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "      )\n",
            "    )\n",
            "  )\n",
            "  (17): ECB(\n",
            "    (patch_embed): PatchEmbed(\n",
            "      (avgpool): Identity()\n",
            "      (conv): Conv2d(512, 384, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
            "      (norm): BatchNorm2d(384, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "    )\n",
            "    (mhca): MHCA(\n",
            "      (group_conv3x3): Conv2d(384, 384, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=12, bias=False)\n",
            "      (norm): BatchNorm2d(384, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "      (act): ReLU(inplace=True)\n",
            "      (projection): Conv2d(384, 384, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
            "    )\n",
            "    (attention_path_dropout): DropPath(drop_prob=0.117)\n",
            "    (conv): LocalityFeedForward(\n",
            "      (conv): Sequential(\n",
            "        (0): Conv2d(384, 1152, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
            "        (1): BatchNorm2d(1152, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "        (2): h_swish(\n",
            "          (sigmoid): h_sigmoid(\n",
            "            (relu): ReLU6(inplace=True)\n",
            "          )\n",
            "        )\n",
            "        (3): Conv2d(1152, 1152, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=1152, bias=False)\n",
            "        (4): BatchNorm2d(1152, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "        (5): h_swish(\n",
            "          (sigmoid): h_sigmoid(\n",
            "            (relu): ReLU6(inplace=True)\n",
            "          )\n",
            "        )\n",
            "        (6): SELayer(\n",
            "          (avg_pool): AdaptiveAvgPool2d(output_size=1)\n",
            "          (fc): Sequential(\n",
            "            (0): Linear(in_features=1152, out_features=3, bias=True)\n",
            "            (1): ReLU(inplace=True)\n",
            "            (2): Linear(in_features=3, out_features=1152, bias=True)\n",
            "            (3): h_sigmoid(\n",
            "              (relu): ReLU6(inplace=True)\n",
            "            )\n",
            "          )\n",
            "        )\n",
            "        (7): Conv2d(1152, 384, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
            "        (8): BatchNorm2d(384, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "      )\n",
            "    )\n",
            "    (norm): BatchNorm2d(384, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "  )\n",
            "  (18): ECB(\n",
            "    (patch_embed): PatchEmbed(\n",
            "      (avgpool): Identity()\n",
            "      (conv): Identity()\n",
            "      (norm): Identity()\n",
            "    )\n",
            "    (mhca): MHCA(\n",
            "      (group_conv3x3): Conv2d(384, 384, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=12, bias=False)\n",
            "      (norm): BatchNorm2d(384, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "      (act): ReLU(inplace=True)\n",
            "      (projection): Conv2d(384, 384, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
            "    )\n",
            "    (attention_path_dropout): DropPath(drop_prob=0.124)\n",
            "    (conv): LocalityFeedForward(\n",
            "      (conv): Sequential(\n",
            "        (0): Conv2d(384, 1152, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
            "        (1): BatchNorm2d(1152, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "        (2): h_swish(\n",
            "          (sigmoid): h_sigmoid(\n",
            "            (relu): ReLU6(inplace=True)\n",
            "          )\n",
            "        )\n",
            "        (3): Conv2d(1152, 1152, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=1152, bias=False)\n",
            "        (4): BatchNorm2d(1152, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "        (5): h_swish(\n",
            "          (sigmoid): h_sigmoid(\n",
            "            (relu): ReLU6(inplace=True)\n",
            "          )\n",
            "        )\n",
            "        (6): SELayer(\n",
            "          (avg_pool): AdaptiveAvgPool2d(output_size=1)\n",
            "          (fc): Sequential(\n",
            "            (0): Linear(in_features=1152, out_features=3, bias=True)\n",
            "            (1): ReLU(inplace=True)\n",
            "            (2): Linear(in_features=3, out_features=1152, bias=True)\n",
            "            (3): h_sigmoid(\n",
            "              (relu): ReLU6(inplace=True)\n",
            "            )\n",
            "          )\n",
            "        )\n",
            "        (7): Conv2d(1152, 384, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
            "        (8): BatchNorm2d(384, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "      )\n",
            "    )\n",
            "    (norm): BatchNorm2d(384, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "  )\n",
            "  (19): ECB(\n",
            "    (patch_embed): PatchEmbed(\n",
            "      (avgpool): Identity()\n",
            "      (conv): Identity()\n",
            "      (norm): Identity()\n",
            "    )\n",
            "    (mhca): MHCA(\n",
            "      (group_conv3x3): Conv2d(384, 384, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=12, bias=False)\n",
            "      (norm): BatchNorm2d(384, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "      (act): ReLU(inplace=True)\n",
            "      (projection): Conv2d(384, 384, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
            "    )\n",
            "    (attention_path_dropout): DropPath(drop_prob=0.131)\n",
            "    (conv): LocalityFeedForward(\n",
            "      (conv): Sequential(\n",
            "        (0): Conv2d(384, 1152, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
            "        (1): BatchNorm2d(1152, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "        (2): h_swish(\n",
            "          (sigmoid): h_sigmoid(\n",
            "            (relu): ReLU6(inplace=True)\n",
            "          )\n",
            "        )\n",
            "        (3): Conv2d(1152, 1152, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=1152, bias=False)\n",
            "        (4): BatchNorm2d(1152, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "        (5): h_swish(\n",
            "          (sigmoid): h_sigmoid(\n",
            "            (relu): ReLU6(inplace=True)\n",
            "          )\n",
            "        )\n",
            "        (6): SELayer(\n",
            "          (avg_pool): AdaptiveAvgPool2d(output_size=1)\n",
            "          (fc): Sequential(\n",
            "            (0): Linear(in_features=1152, out_features=3, bias=True)\n",
            "            (1): ReLU(inplace=True)\n",
            "            (2): Linear(in_features=3, out_features=1152, bias=True)\n",
            "            (3): h_sigmoid(\n",
            "              (relu): ReLU6(inplace=True)\n",
            "            )\n",
            "          )\n",
            "        )\n",
            "        (7): Conv2d(1152, 384, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
            "        (8): BatchNorm2d(384, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "      )\n",
            "    )\n",
            "    (norm): BatchNorm2d(384, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "  )\n",
            "  (20): ECB(\n",
            "    (patch_embed): PatchEmbed(\n",
            "      (avgpool): Identity()\n",
            "      (conv): Identity()\n",
            "      (norm): Identity()\n",
            "    )\n",
            "    (mhca): MHCA(\n",
            "      (group_conv3x3): Conv2d(384, 384, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=12, bias=False)\n",
            "      (norm): BatchNorm2d(384, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "      (act): ReLU(inplace=True)\n",
            "      (projection): Conv2d(384, 384, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
            "    )\n",
            "    (attention_path_dropout): DropPath(drop_prob=0.138)\n",
            "    (conv): LocalityFeedForward(\n",
            "      (conv): Sequential(\n",
            "        (0): Conv2d(384, 1152, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
            "        (1): BatchNorm2d(1152, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "        (2): h_swish(\n",
            "          (sigmoid): h_sigmoid(\n",
            "            (relu): ReLU6(inplace=True)\n",
            "          )\n",
            "        )\n",
            "        (3): Conv2d(1152, 1152, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=1152, bias=False)\n",
            "        (4): BatchNorm2d(1152, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "        (5): h_swish(\n",
            "          (sigmoid): h_sigmoid(\n",
            "            (relu): ReLU6(inplace=True)\n",
            "          )\n",
            "        )\n",
            "        (6): SELayer(\n",
            "          (avg_pool): AdaptiveAvgPool2d(output_size=1)\n",
            "          (fc): Sequential(\n",
            "            (0): Linear(in_features=1152, out_features=3, bias=True)\n",
            "            (1): ReLU(inplace=True)\n",
            "            (2): Linear(in_features=3, out_features=1152, bias=True)\n",
            "            (3): h_sigmoid(\n",
            "              (relu): ReLU6(inplace=True)\n",
            "            )\n",
            "          )\n",
            "        )\n",
            "        (7): Conv2d(1152, 384, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
            "        (8): BatchNorm2d(384, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "      )\n",
            "    )\n",
            "    (norm): BatchNorm2d(384, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "  )\n",
            "  (21): LTB(\n",
            "    (patch_embed): PatchEmbed(\n",
            "      (avgpool): Identity()\n",
            "      (conv): Identity()\n",
            "      (norm): Identity()\n",
            "    )\n",
            "    (norm1): BatchNorm2d(384, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "    (e_mhsa): E_MHSA(\n",
            "      (q): Linear(in_features=384, out_features=384, bias=True)\n",
            "      (k): Linear(in_features=384, out_features=384, bias=True)\n",
            "      (v): Linear(in_features=384, out_features=384, bias=True)\n",
            "      (proj): Linear(in_features=384, out_features=384, bias=True)\n",
            "      (attn_drop): Dropout(p=0, inplace=False)\n",
            "      (proj_drop): Dropout(p=0, inplace=False)\n",
            "      (sr): AvgPool1d(kernel_size=(4,), stride=(4,), padding=(0,))\n",
            "      (norm): BatchNorm1d(384, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "    )\n",
            "    (mhsa_path_dropout): DropPath(drop_prob=0.109)\n",
            "    (projection): PatchEmbed(\n",
            "      (avgpool): Identity()\n",
            "      (conv): Conv2d(384, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
            "      (norm): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "    )\n",
            "    (mhca): MHCA(\n",
            "      (group_conv3x3): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=4, bias=False)\n",
            "      (norm): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "      (act): ReLU(inplace=True)\n",
            "      (projection): Conv2d(128, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
            "    )\n",
            "    (mhca_path_dropout): DropPath(drop_prob=0.036)\n",
            "    (norm2): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "    (conv): LocalityFeedForward(\n",
            "      (conv): Sequential(\n",
            "        (0): Conv2d(512, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
            "        (1): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "        (2): h_swish(\n",
            "          (sigmoid): h_sigmoid(\n",
            "            (relu): ReLU6(inplace=True)\n",
            "          )\n",
            "        )\n",
            "        (3): Conv2d(1024, 1024, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=1024, bias=False)\n",
            "        (4): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "        (5): h_swish(\n",
            "          (sigmoid): h_sigmoid(\n",
            "            (relu): ReLU6(inplace=True)\n",
            "          )\n",
            "        )\n",
            "        (6): SELayer(\n",
            "          (avg_pool): AdaptiveAvgPool2d(output_size=1)\n",
            "          (fc): Sequential(\n",
            "            (0): Linear(in_features=1024, out_features=2, bias=True)\n",
            "            (1): ReLU(inplace=True)\n",
            "            (2): Linear(in_features=2, out_features=1024, bias=True)\n",
            "            (3): h_sigmoid(\n",
            "              (relu): ReLU6(inplace=True)\n",
            "            )\n",
            "          )\n",
            "        )\n",
            "        (7): Conv2d(1024, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
            "        (8): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "      )\n",
            "    )\n",
            "  )\n",
            "  (22): ECB(\n",
            "    (patch_embed): PatchEmbed(\n",
            "      (avgpool): Identity()\n",
            "      (conv): Conv2d(512, 384, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
            "      (norm): BatchNorm2d(384, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "    )\n",
            "    (mhca): MHCA(\n",
            "      (group_conv3x3): Conv2d(384, 384, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=12, bias=False)\n",
            "      (norm): BatchNorm2d(384, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "      (act): ReLU(inplace=True)\n",
            "      (projection): Conv2d(384, 384, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
            "    )\n",
            "    (attention_path_dropout): DropPath(drop_prob=0.152)\n",
            "    (conv): LocalityFeedForward(\n",
            "      (conv): Sequential(\n",
            "        (0): Conv2d(384, 1152, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
            "        (1): BatchNorm2d(1152, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "        (2): h_swish(\n",
            "          (sigmoid): h_sigmoid(\n",
            "            (relu): ReLU6(inplace=True)\n",
            "          )\n",
            "        )\n",
            "        (3): Conv2d(1152, 1152, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=1152, bias=False)\n",
            "        (4): BatchNorm2d(1152, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "        (5): h_swish(\n",
            "          (sigmoid): h_sigmoid(\n",
            "            (relu): ReLU6(inplace=True)\n",
            "          )\n",
            "        )\n",
            "        (6): SELayer(\n",
            "          (avg_pool): AdaptiveAvgPool2d(output_size=1)\n",
            "          (fc): Sequential(\n",
            "            (0): Linear(in_features=1152, out_features=3, bias=True)\n",
            "            (1): ReLU(inplace=True)\n",
            "            (2): Linear(in_features=3, out_features=1152, bias=True)\n",
            "            (3): h_sigmoid(\n",
            "              (relu): ReLU6(inplace=True)\n",
            "            )\n",
            "          )\n",
            "        )\n",
            "        (7): Conv2d(1152, 384, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
            "        (8): BatchNorm2d(384, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "      )\n",
            "    )\n",
            "    (norm): BatchNorm2d(384, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "  )\n",
            "  (23): ECB(\n",
            "    (patch_embed): PatchEmbed(\n",
            "      (avgpool): Identity()\n",
            "      (conv): Identity()\n",
            "      (norm): Identity()\n",
            "    )\n",
            "    (mhca): MHCA(\n",
            "      (group_conv3x3): Conv2d(384, 384, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=12, bias=False)\n",
            "      (norm): BatchNorm2d(384, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "      (act): ReLU(inplace=True)\n",
            "      (projection): Conv2d(384, 384, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
            "    )\n",
            "    (attention_path_dropout): DropPath(drop_prob=0.159)\n",
            "    (conv): LocalityFeedForward(\n",
            "      (conv): Sequential(\n",
            "        (0): Conv2d(384, 1152, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
            "        (1): BatchNorm2d(1152, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "        (2): h_swish(\n",
            "          (sigmoid): h_sigmoid(\n",
            "            (relu): ReLU6(inplace=True)\n",
            "          )\n",
            "        )\n",
            "        (3): Conv2d(1152, 1152, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=1152, bias=False)\n",
            "        (4): BatchNorm2d(1152, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "        (5): h_swish(\n",
            "          (sigmoid): h_sigmoid(\n",
            "            (relu): ReLU6(inplace=True)\n",
            "          )\n",
            "        )\n",
            "        (6): SELayer(\n",
            "          (avg_pool): AdaptiveAvgPool2d(output_size=1)\n",
            "          (fc): Sequential(\n",
            "            (0): Linear(in_features=1152, out_features=3, bias=True)\n",
            "            (1): ReLU(inplace=True)\n",
            "            (2): Linear(in_features=3, out_features=1152, bias=True)\n",
            "            (3): h_sigmoid(\n",
            "              (relu): ReLU6(inplace=True)\n",
            "            )\n",
            "          )\n",
            "        )\n",
            "        (7): Conv2d(1152, 384, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
            "        (8): BatchNorm2d(384, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "      )\n",
            "    )\n",
            "    (norm): BatchNorm2d(384, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "  )\n",
            "  (24): ECB(\n",
            "    (patch_embed): PatchEmbed(\n",
            "      (avgpool): Identity()\n",
            "      (conv): Identity()\n",
            "      (norm): Identity()\n",
            "    )\n",
            "    (mhca): MHCA(\n",
            "      (group_conv3x3): Conv2d(384, 384, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=12, bias=False)\n",
            "      (norm): BatchNorm2d(384, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "      (act): ReLU(inplace=True)\n",
            "      (projection): Conv2d(384, 384, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
            "    )\n",
            "    (attention_path_dropout): DropPath(drop_prob=0.166)\n",
            "    (conv): LocalityFeedForward(\n",
            "      (conv): Sequential(\n",
            "        (0): Conv2d(384, 1152, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
            "        (1): BatchNorm2d(1152, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "        (2): h_swish(\n",
            "          (sigmoid): h_sigmoid(\n",
            "            (relu): ReLU6(inplace=True)\n",
            "          )\n",
            "        )\n",
            "        (3): Conv2d(1152, 1152, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=1152, bias=False)\n",
            "        (4): BatchNorm2d(1152, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "        (5): h_swish(\n",
            "          (sigmoid): h_sigmoid(\n",
            "            (relu): ReLU6(inplace=True)\n",
            "          )\n",
            "        )\n",
            "        (6): SELayer(\n",
            "          (avg_pool): AdaptiveAvgPool2d(output_size=1)\n",
            "          (fc): Sequential(\n",
            "            (0): Linear(in_features=1152, out_features=3, bias=True)\n",
            "            (1): ReLU(inplace=True)\n",
            "            (2): Linear(in_features=3, out_features=1152, bias=True)\n",
            "            (3): h_sigmoid(\n",
            "              (relu): ReLU6(inplace=True)\n",
            "            )\n",
            "          )\n",
            "        )\n",
            "        (7): Conv2d(1152, 384, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
            "        (8): BatchNorm2d(384, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "      )\n",
            "    )\n",
            "    (norm): BatchNorm2d(384, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "  )\n",
            "  (25): ECB(\n",
            "    (patch_embed): PatchEmbed(\n",
            "      (avgpool): Identity()\n",
            "      (conv): Identity()\n",
            "      (norm): Identity()\n",
            "    )\n",
            "    (mhca): MHCA(\n",
            "      (group_conv3x3): Conv2d(384, 384, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=12, bias=False)\n",
            "      (norm): BatchNorm2d(384, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "      (act): ReLU(inplace=True)\n",
            "      (projection): Conv2d(384, 384, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
            "    )\n",
            "    (attention_path_dropout): DropPath(drop_prob=0.172)\n",
            "    (conv): LocalityFeedForward(\n",
            "      (conv): Sequential(\n",
            "        (0): Conv2d(384, 1152, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
            "        (1): BatchNorm2d(1152, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "        (2): h_swish(\n",
            "          (sigmoid): h_sigmoid(\n",
            "            (relu): ReLU6(inplace=True)\n",
            "          )\n",
            "        )\n",
            "        (3): Conv2d(1152, 1152, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=1152, bias=False)\n",
            "        (4): BatchNorm2d(1152, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "        (5): h_swish(\n",
            "          (sigmoid): h_sigmoid(\n",
            "            (relu): ReLU6(inplace=True)\n",
            "          )\n",
            "        )\n",
            "        (6): SELayer(\n",
            "          (avg_pool): AdaptiveAvgPool2d(output_size=1)\n",
            "          (fc): Sequential(\n",
            "            (0): Linear(in_features=1152, out_features=3, bias=True)\n",
            "            (1): ReLU(inplace=True)\n",
            "            (2): Linear(in_features=3, out_features=1152, bias=True)\n",
            "            (3): h_sigmoid(\n",
            "              (relu): ReLU6(inplace=True)\n",
            "            )\n",
            "          )\n",
            "        )\n",
            "        (7): Conv2d(1152, 384, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
            "        (8): BatchNorm2d(384, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "      )\n",
            "    )\n",
            "    (norm): BatchNorm2d(384, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "  )\n",
            "  (26): LTB(\n",
            "    (patch_embed): PatchEmbed(\n",
            "      (avgpool): Identity()\n",
            "      (conv): Identity()\n",
            "      (norm): Identity()\n",
            "    )\n",
            "    (norm1): BatchNorm2d(384, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "    (e_mhsa): E_MHSA(\n",
            "      (q): Linear(in_features=384, out_features=384, bias=True)\n",
            "      (k): Linear(in_features=384, out_features=384, bias=True)\n",
            "      (v): Linear(in_features=384, out_features=384, bias=True)\n",
            "      (proj): Linear(in_features=384, out_features=384, bias=True)\n",
            "      (attn_drop): Dropout(p=0, inplace=False)\n",
            "      (proj_drop): Dropout(p=0, inplace=False)\n",
            "      (sr): AvgPool1d(kernel_size=(4,), stride=(4,), padding=(0,))\n",
            "      (norm): BatchNorm1d(384, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "    )\n",
            "    (mhsa_path_dropout): DropPath(drop_prob=0.134)\n",
            "    (projection): PatchEmbed(\n",
            "      (avgpool): Identity()\n",
            "      (conv): Conv2d(384, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
            "      (norm): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "    )\n",
            "    (mhca): MHCA(\n",
            "      (group_conv3x3): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=4, bias=False)\n",
            "      (norm): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "      (act): ReLU(inplace=True)\n",
            "      (projection): Conv2d(128, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
            "    )\n",
            "    (mhca_path_dropout): DropPath(drop_prob=0.045)\n",
            "    (norm2): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "    (conv): LocalityFeedForward(\n",
            "      (conv): Sequential(\n",
            "        (0): Conv2d(512, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
            "        (1): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "        (2): h_swish(\n",
            "          (sigmoid): h_sigmoid(\n",
            "            (relu): ReLU6(inplace=True)\n",
            "          )\n",
            "        )\n",
            "        (3): Conv2d(1024, 1024, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=1024, bias=False)\n",
            "        (4): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "        (5): h_swish(\n",
            "          (sigmoid): h_sigmoid(\n",
            "            (relu): ReLU6(inplace=True)\n",
            "          )\n",
            "        )\n",
            "        (6): SELayer(\n",
            "          (avg_pool): AdaptiveAvgPool2d(output_size=1)\n",
            "          (fc): Sequential(\n",
            "            (0): Linear(in_features=1024, out_features=2, bias=True)\n",
            "            (1): ReLU(inplace=True)\n",
            "            (2): Linear(in_features=2, out_features=1024, bias=True)\n",
            "            (3): h_sigmoid(\n",
            "              (relu): ReLU6(inplace=True)\n",
            "            )\n",
            "          )\n",
            "        )\n",
            "        (7): Conv2d(1024, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
            "        (8): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "      )\n",
            "    )\n",
            "  )\n",
            "  (27): ECB(\n",
            "    (patch_embed): PatchEmbed(\n",
            "      (avgpool): AvgPool2d(kernel_size=(2, 2), stride=2, padding=0)\n",
            "      (conv): Conv2d(512, 768, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
            "      (norm): BatchNorm2d(768, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "    )\n",
            "    (mhca): MHCA(\n",
            "      (group_conv3x3): Conv2d(768, 768, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=24, bias=False)\n",
            "      (norm): BatchNorm2d(768, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "      (act): ReLU(inplace=True)\n",
            "      (projection): Conv2d(768, 768, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
            "    )\n",
            "    (attention_path_dropout): DropPath(drop_prob=0.186)\n",
            "    (conv): LocalityFeedForward(\n",
            "      (conv): Sequential(\n",
            "        (0): Conv2d(768, 2304, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
            "        (1): BatchNorm2d(2304, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "        (2): h_swish(\n",
            "          (sigmoid): h_sigmoid(\n",
            "            (relu): ReLU6(inplace=True)\n",
            "          )\n",
            "        )\n",
            "        (3): Conv2d(2304, 2304, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=2304, bias=False)\n",
            "        (4): BatchNorm2d(2304, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "        (5): h_swish(\n",
            "          (sigmoid): h_sigmoid(\n",
            "            (relu): ReLU6(inplace=True)\n",
            "          )\n",
            "        )\n",
            "        (6): SELayer(\n",
            "          (avg_pool): AdaptiveAvgPool2d(output_size=1)\n",
            "          (fc): Sequential(\n",
            "            (0): Linear(in_features=2304, out_features=3, bias=True)\n",
            "            (1): ReLU(inplace=True)\n",
            "            (2): Linear(in_features=3, out_features=2304, bias=True)\n",
            "            (3): h_sigmoid(\n",
            "              (relu): ReLU6(inplace=True)\n",
            "            )\n",
            "          )\n",
            "        )\n",
            "        (7): Conv2d(2304, 768, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
            "        (8): BatchNorm2d(768, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "      )\n",
            "    )\n",
            "    (norm): BatchNorm2d(768, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "  )\n",
            "  (28): ECB(\n",
            "    (patch_embed): PatchEmbed(\n",
            "      (avgpool): Identity()\n",
            "      (conv): Identity()\n",
            "      (norm): Identity()\n",
            "    )\n",
            "    (mhca): MHCA(\n",
            "      (group_conv3x3): Conv2d(768, 768, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=24, bias=False)\n",
            "      (norm): BatchNorm2d(768, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "      (act): ReLU(inplace=True)\n",
            "      (projection): Conv2d(768, 768, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
            "    )\n",
            "    (attention_path_dropout): DropPath(drop_prob=0.193)\n",
            "    (conv): LocalityFeedForward(\n",
            "      (conv): Sequential(\n",
            "        (0): Conv2d(768, 2304, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
            "        (1): BatchNorm2d(2304, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "        (2): h_swish(\n",
            "          (sigmoid): h_sigmoid(\n",
            "            (relu): ReLU6(inplace=True)\n",
            "          )\n",
            "        )\n",
            "        (3): Conv2d(2304, 2304, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=2304, bias=False)\n",
            "        (4): BatchNorm2d(2304, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "        (5): h_swish(\n",
            "          (sigmoid): h_sigmoid(\n",
            "            (relu): ReLU6(inplace=True)\n",
            "          )\n",
            "        )\n",
            "        (6): SELayer(\n",
            "          (avg_pool): AdaptiveAvgPool2d(output_size=1)\n",
            "          (fc): Sequential(\n",
            "            (0): Linear(in_features=2304, out_features=3, bias=True)\n",
            "            (1): ReLU(inplace=True)\n",
            "            (2): Linear(in_features=3, out_features=2304, bias=True)\n",
            "            (3): h_sigmoid(\n",
            "              (relu): ReLU6(inplace=True)\n",
            "            )\n",
            "          )\n",
            "        )\n",
            "        (7): Conv2d(2304, 768, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
            "        (8): BatchNorm2d(768, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "      )\n",
            "    )\n",
            "    (norm): BatchNorm2d(768, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "  )\n",
            "  (29): LTB(\n",
            "    (patch_embed): PatchEmbed(\n",
            "      (avgpool): Identity()\n",
            "      (conv): Identity()\n",
            "      (norm): Identity()\n",
            "    )\n",
            "    (norm1): BatchNorm2d(768, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "    (e_mhsa): E_MHSA(\n",
            "      (q): Linear(in_features=768, out_features=768, bias=True)\n",
            "      (k): Linear(in_features=768, out_features=768, bias=True)\n",
            "      (v): Linear(in_features=768, out_features=768, bias=True)\n",
            "      (proj): Linear(in_features=768, out_features=768, bias=True)\n",
            "      (attn_drop): Dropout(p=0, inplace=False)\n",
            "      (proj_drop): Dropout(p=0, inplace=False)\n",
            "    )\n",
            "    (mhsa_path_dropout): DropPath(drop_prob=0.150)\n",
            "    (projection): PatchEmbed(\n",
            "      (avgpool): Identity()\n",
            "      (conv): Conv2d(768, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
            "      (norm): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "    )\n",
            "    (mhca): MHCA(\n",
            "      (group_conv3x3): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=8, bias=False)\n",
            "      (norm): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "      (act): ReLU(inplace=True)\n",
            "      (projection): Conv2d(256, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
            "    )\n",
            "    (mhca_path_dropout): DropPath(drop_prob=0.050)\n",
            "    (norm2): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "    (conv): LocalityFeedForward(\n",
            "      (conv): Sequential(\n",
            "        (0): Conv2d(1024, 2048, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
            "        (1): BatchNorm2d(2048, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "        (2): h_swish(\n",
            "          (sigmoid): h_sigmoid(\n",
            "            (relu): ReLU6(inplace=True)\n",
            "          )\n",
            "        )\n",
            "        (3): Conv2d(2048, 2048, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=2048, bias=False)\n",
            "        (4): BatchNorm2d(2048, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "        (5): h_swish(\n",
            "          (sigmoid): h_sigmoid(\n",
            "            (relu): ReLU6(inplace=True)\n",
            "          )\n",
            "        )\n",
            "        (6): SELayer(\n",
            "          (avg_pool): AdaptiveAvgPool2d(output_size=1)\n",
            "          (fc): Sequential(\n",
            "            (0): Linear(in_features=2048, out_features=2, bias=True)\n",
            "            (1): ReLU(inplace=True)\n",
            "            (2): Linear(in_features=2, out_features=2048, bias=True)\n",
            "            (3): h_sigmoid(\n",
            "              (relu): ReLU6(inplace=True)\n",
            "            )\n",
            "          )\n",
            "        )\n",
            "        (7): Conv2d(2048, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
            "        (8): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "      )\n",
            "    )\n",
            "  )\n",
            ")\n",
            "RAW FEATURE MAP SHAPE: torch.Size([1, 768, 7, 7])\n",
            "Raw heatmap resolution: 7x7\n",
            "RAW FEATURE MAP SHAPE: torch.Size([1, 768, 7, 7])\n",
            "Raw heatmap resolution: 7x7\n",
            "RAW FEATURE MAP SHAPE: torch.Size([1, 768, 7, 7])\n",
            "Raw heatmap resolution: 7x7\n",
            "RAW FEATURE MAP SHAPE: torch.Size([1, 768, 7, 7])\n",
            "Raw heatmap resolution: 7x7\n",
            "RAW FEATURE MAP SHAPE: torch.Size([1, 768, 7, 7])\n",
            "Raw heatmap resolution: 7x7\n",
            "RAW FEATURE MAP SHAPE: torch.Size([1, 768, 7, 7])\n",
            "Raw heatmap resolution: 7x7\n",
            "RAW FEATURE MAP SHAPE: torch.Size([1, 768, 7, 7])\n",
            "Raw heatmap resolution: 7x7\n",
            "RAW FEATURE MAP SHAPE: torch.Size([1, 768, 7, 7])\n",
            "Raw heatmap resolution: 7x7\n",
            "RAW FEATURE MAP SHAPE: torch.Size([1, 768, 7, 7])\n",
            "Raw heatmap resolution: 7x7\n",
            "RAW FEATURE MAP SHAPE: torch.Size([1, 768, 7, 7])\n",
            "Raw heatmap resolution: 7x7\n",
            "RAW FEATURE MAP SHAPE: torch.Size([1, 768, 7, 7])\n",
            "Raw heatmap resolution: 7x7\n"
          ]
        },
        {
          "ename": "KeyboardInterrupt",
          "evalue": "",
          "output_type": "error",
          "traceback": [
            "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[1;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
            "Cell \u001b[1;32mIn[9], line 59\u001b[0m\n\u001b[0;32m     56\u001b[0m     \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mAll Grad-CAM heatmaps were generated successfully.\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[0;32m     58\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;18m__name__\u001b[39m \u001b[38;5;241m==\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m__main__\u001b[39m\u001b[38;5;124m\"\u001b[39m:\n\u001b[1;32m---> 59\u001b[0m     \u001b[43mmain\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n",
            "Cell \u001b[1;32mIn[9], line 34\u001b[0m, in \u001b[0;36mmain\u001b[1;34m()\u001b[0m\n\u001b[0;32m     32\u001b[0m                 \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mProcessing: \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mstructure\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m, \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mbirth_type\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m, \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mdataset\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m, \u001b[39m\u001b[38;5;132;01m{\u001b[39;00msplit\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m\"\u001b[39m)\n\u001b[0;32m     33\u001b[0m                 model \u001b[38;5;241m=\u001b[39m load_medvit_model(weight_path, num_classes\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m2\u001b[39m)\n\u001b[1;32m---> 34\u001b[0m                 all_heatmaps, original_images \u001b[38;5;241m=\u001b[39m \u001b[43mapply_gradcam_and_save\u001b[49m\u001b[43m(\u001b[49m\u001b[43mmodel\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43minput_folder\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43moutput_folder\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m     36\u001b[0m \u001b[38;5;250m                \u001b[39m\u001b[38;5;124;03m\"\"\"df = generate_prediction_table_only(\u001b[39;00m\n\u001b[0;32m     37\u001b[0m \u001b[38;5;124;03m                        model=model,\u001b[39;00m\n\u001b[0;32m     38\u001b[0m \u001b[38;5;124;03m                        input_folder=input_folder,\u001b[39;00m\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m     53\u001b[0m \u001b[38;5;124;03m            df.to_excel(writer, sheet_name=sheet_name, index=False)\u001b[39;00m\n\u001b[0;32m     54\u001b[0m \u001b[38;5;124;03m    print(f\"Guardado: {excel_path}\")\"\"\"\u001b[39;00m\n\u001b[0;32m     56\u001b[0m \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mAll Grad-CAM heatmaps were generated successfully.\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n",
            "Cell \u001b[1;32mIn[7], line 39\u001b[0m, in \u001b[0;36mapply_gradcam_and_save\u001b[1;34m(model, input_folder, output_folder, grid_image_size)\u001b[0m\n\u001b[0;32m     37\u001b[0m \u001b[38;5;66;03m# Previsão para obter classe\u001b[39;00m\n\u001b[0;32m     38\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m torch\u001b[38;5;241m.\u001b[39mno_grad():\n\u001b[1;32m---> 39\u001b[0m     output \u001b[38;5;241m=\u001b[39m \u001b[43mmodel\u001b[49m\u001b[43m(\u001b[49m\u001b[43minput_tensor\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m     40\u001b[0m     prediction \u001b[38;5;241m=\u001b[39m output\u001b[38;5;241m.\u001b[39margmax(dim\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m1\u001b[39m)\u001b[38;5;241m.\u001b[39mitem()\n\u001b[0;32m     41\u001b[0m     probabilities \u001b[38;5;241m=\u001b[39m torch\u001b[38;5;241m.\u001b[39msoftmax(output, dim\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m1\u001b[39m)\n",
            "File \u001b[1;32mc:\\Users\\anale\\miniconda3\\envs\\leonorjacob-tese\\lib\\site-packages\\torch\\nn\\modules\\module.py:1736\u001b[0m, in \u001b[0;36mModule._wrapped_call_impl\u001b[1;34m(self, *args, **kwargs)\u001b[0m\n\u001b[0;32m   1734\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_compiled_call_impl(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)  \u001b[38;5;66;03m# type: ignore[misc]\u001b[39;00m\n\u001b[0;32m   1735\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m-> 1736\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_call_impl(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n",
            "File \u001b[1;32mc:\\Users\\anale\\miniconda3\\envs\\leonorjacob-tese\\lib\\site-packages\\torch\\nn\\modules\\module.py:1747\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[1;34m(self, *args, **kwargs)\u001b[0m\n\u001b[0;32m   1742\u001b[0m \u001b[38;5;66;03m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[0;32m   1743\u001b[0m \u001b[38;5;66;03m# this function, and just call forward.\u001b[39;00m\n\u001b[0;32m   1744\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m (\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_pre_hooks\n\u001b[0;32m   1745\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_backward_hooks\n\u001b[0;32m   1746\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[1;32m-> 1747\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m forward_call(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n\u001b[0;32m   1749\u001b[0m result \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[0;32m   1750\u001b[0m called_always_called_hooks \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mset\u001b[39m()\n",
            "File \u001b[1;32mc:\\Users\\anale\\OneDrive\\Documentos\\Universidade\\TESE\\MSc-Thesis\\MedViT_model.py:506\u001b[0m, in \u001b[0;36mMedViT.forward\u001b[1;34m(self, x)\u001b[0m\n\u001b[0;32m    504\u001b[0m         x \u001b[38;5;241m=\u001b[39m checkpoint\u001b[38;5;241m.\u001b[39mcheckpoint(layer, x)\n\u001b[0;32m    505\u001b[0m     \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m--> 506\u001b[0m         x \u001b[38;5;241m=\u001b[39m \u001b[43mlayer\u001b[49m\u001b[43m(\u001b[49m\u001b[43mx\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    507\u001b[0m x \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mnorm(x)\n\u001b[0;32m    508\u001b[0m x \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mavgpool(x)\n",
            "File \u001b[1;32mc:\\Users\\anale\\miniconda3\\envs\\leonorjacob-tese\\lib\\site-packages\\torch\\nn\\modules\\module.py:1736\u001b[0m, in \u001b[0;36mModule._wrapped_call_impl\u001b[1;34m(self, *args, **kwargs)\u001b[0m\n\u001b[0;32m   1734\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_compiled_call_impl(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)  \u001b[38;5;66;03m# type: ignore[misc]\u001b[39;00m\n\u001b[0;32m   1735\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m-> 1736\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_call_impl(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n",
            "File \u001b[1;32mc:\\Users\\anale\\miniconda3\\envs\\leonorjacob-tese\\lib\\site-packages\\torch\\nn\\modules\\module.py:1747\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[1;34m(self, *args, **kwargs)\u001b[0m\n\u001b[0;32m   1742\u001b[0m \u001b[38;5;66;03m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[0;32m   1743\u001b[0m \u001b[38;5;66;03m# this function, and just call forward.\u001b[39;00m\n\u001b[0;32m   1744\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m (\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_pre_hooks\n\u001b[0;32m   1745\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_backward_hooks\n\u001b[0;32m   1746\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[1;32m-> 1747\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m forward_call(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n\u001b[0;32m   1749\u001b[0m result \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[0;32m   1750\u001b[0m called_always_called_hooks \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mset\u001b[39m()\n",
            "File \u001b[1;32mc:\\Users\\anale\\OneDrive\\Documentos\\Universidade\\TESE\\MSc-Thesis\\MedViT_model.py:274\u001b[0m, in \u001b[0;36mECB.forward\u001b[1;34m(self, x)\u001b[0m\n\u001b[0;32m    272\u001b[0m     out \u001b[38;5;241m=\u001b[39m x\n\u001b[0;32m    273\u001b[0m \u001b[38;5;66;03m#x = x + self.mlp_path_dropout(self.mlp(out))\u001b[39;00m\n\u001b[1;32m--> 274\u001b[0m x \u001b[38;5;241m=\u001b[39m x \u001b[38;5;241m+\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mconv\u001b[49m\u001b[43m(\u001b[49m\u001b[43mout\u001b[49m\u001b[43m)\u001b[49m \u001b[38;5;66;03m# (B, dim, 14, 14)\u001b[39;00m\n\u001b[0;32m    275\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m x\n",
            "File \u001b[1;32mc:\\Users\\anale\\miniconda3\\envs\\leonorjacob-tese\\lib\\site-packages\\torch\\nn\\modules\\module.py:1736\u001b[0m, in \u001b[0;36mModule._wrapped_call_impl\u001b[1;34m(self, *args, **kwargs)\u001b[0m\n\u001b[0;32m   1734\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_compiled_call_impl(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)  \u001b[38;5;66;03m# type: ignore[misc]\u001b[39;00m\n\u001b[0;32m   1735\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m-> 1736\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_call_impl(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n",
            "File \u001b[1;32mc:\\Users\\anale\\miniconda3\\envs\\leonorjacob-tese\\lib\\site-packages\\torch\\nn\\modules\\module.py:1747\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[1;34m(self, *args, **kwargs)\u001b[0m\n\u001b[0;32m   1742\u001b[0m \u001b[38;5;66;03m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[0;32m   1743\u001b[0m \u001b[38;5;66;03m# this function, and just call forward.\u001b[39;00m\n\u001b[0;32m   1744\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m (\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_pre_hooks\n\u001b[0;32m   1745\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_backward_hooks\n\u001b[0;32m   1746\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[1;32m-> 1747\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m forward_call(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n\u001b[0;32m   1749\u001b[0m result \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[0;32m   1750\u001b[0m called_always_called_hooks \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mset\u001b[39m()\n",
            "File \u001b[1;32mc:\\Users\\anale\\OneDrive\\Documentos\\Universidade\\TESE\\MSc-Thesis\\MedViT_model.py:212\u001b[0m, in \u001b[0;36mLocalityFeedForward.forward\u001b[1;34m(self, x)\u001b[0m\n\u001b[0;32m    211\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mforward\u001b[39m(\u001b[38;5;28mself\u001b[39m, x):\n\u001b[1;32m--> 212\u001b[0m     x \u001b[38;5;241m=\u001b[39m x \u001b[38;5;241m+\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mconv\u001b[49m\u001b[43m(\u001b[49m\u001b[43mx\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    213\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m x\n",
            "File \u001b[1;32mc:\\Users\\anale\\miniconda3\\envs\\leonorjacob-tese\\lib\\site-packages\\torch\\nn\\modules\\module.py:1736\u001b[0m, in \u001b[0;36mModule._wrapped_call_impl\u001b[1;34m(self, *args, **kwargs)\u001b[0m\n\u001b[0;32m   1734\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_compiled_call_impl(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)  \u001b[38;5;66;03m# type: ignore[misc]\u001b[39;00m\n\u001b[0;32m   1735\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m-> 1736\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_call_impl(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n",
            "File \u001b[1;32mc:\\Users\\anale\\miniconda3\\envs\\leonorjacob-tese\\lib\\site-packages\\torch\\nn\\modules\\module.py:1747\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[1;34m(self, *args, **kwargs)\u001b[0m\n\u001b[0;32m   1742\u001b[0m \u001b[38;5;66;03m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[0;32m   1743\u001b[0m \u001b[38;5;66;03m# this function, and just call forward.\u001b[39;00m\n\u001b[0;32m   1744\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m (\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_pre_hooks\n\u001b[0;32m   1745\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_backward_hooks\n\u001b[0;32m   1746\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[1;32m-> 1747\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m forward_call(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n\u001b[0;32m   1749\u001b[0m result \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[0;32m   1750\u001b[0m called_always_called_hooks \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mset\u001b[39m()\n",
            "File \u001b[1;32mc:\\Users\\anale\\miniconda3\\envs\\leonorjacob-tese\\lib\\site-packages\\torch\\nn\\modules\\container.py:250\u001b[0m, in \u001b[0;36mSequential.forward\u001b[1;34m(self, input)\u001b[0m\n\u001b[0;32m    248\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mforward\u001b[39m(\u001b[38;5;28mself\u001b[39m, \u001b[38;5;28minput\u001b[39m):\n\u001b[0;32m    249\u001b[0m     \u001b[38;5;28;01mfor\u001b[39;00m module \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mself\u001b[39m:\n\u001b[1;32m--> 250\u001b[0m         \u001b[38;5;28minput\u001b[39m \u001b[38;5;241m=\u001b[39m \u001b[43mmodule\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43minput\u001b[39;49m\u001b[43m)\u001b[49m\n\u001b[0;32m    251\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28minput\u001b[39m\n",
            "File \u001b[1;32mc:\\Users\\anale\\miniconda3\\envs\\leonorjacob-tese\\lib\\site-packages\\torch\\nn\\modules\\module.py:1736\u001b[0m, in \u001b[0;36mModule._wrapped_call_impl\u001b[1;34m(self, *args, **kwargs)\u001b[0m\n\u001b[0;32m   1734\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_compiled_call_impl(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)  \u001b[38;5;66;03m# type: ignore[misc]\u001b[39;00m\n\u001b[0;32m   1735\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m-> 1736\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_call_impl(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n",
            "File \u001b[1;32mc:\\Users\\anale\\miniconda3\\envs\\leonorjacob-tese\\lib\\site-packages\\torch\\nn\\modules\\module.py:1747\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[1;34m(self, *args, **kwargs)\u001b[0m\n\u001b[0;32m   1742\u001b[0m \u001b[38;5;66;03m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[0;32m   1743\u001b[0m \u001b[38;5;66;03m# this function, and just call forward.\u001b[39;00m\n\u001b[0;32m   1744\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m (\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_pre_hooks\n\u001b[0;32m   1745\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_backward_hooks\n\u001b[0;32m   1746\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[1;32m-> 1747\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m forward_call(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n\u001b[0;32m   1749\u001b[0m result \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[0;32m   1750\u001b[0m called_always_called_hooks \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mset\u001b[39m()\n",
            "File \u001b[1;32mc:\\Users\\anale\\miniconda3\\envs\\leonorjacob-tese\\lib\\site-packages\\torch\\nn\\modules\\conv.py:554\u001b[0m, in \u001b[0;36mConv2d.forward\u001b[1;34m(self, input)\u001b[0m\n\u001b[0;32m    553\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mforward\u001b[39m(\u001b[38;5;28mself\u001b[39m, \u001b[38;5;28minput\u001b[39m: Tensor) \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m>\u001b[39m Tensor:\n\u001b[1;32m--> 554\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_conv_forward\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43minput\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mweight\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mbias\u001b[49m\u001b[43m)\u001b[49m\n",
            "File \u001b[1;32mc:\\Users\\anale\\miniconda3\\envs\\leonorjacob-tese\\lib\\site-packages\\torch\\nn\\modules\\conv.py:549\u001b[0m, in \u001b[0;36mConv2d._conv_forward\u001b[1;34m(self, input, weight, bias)\u001b[0m\n\u001b[0;32m    537\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mpadding_mode \u001b[38;5;241m!=\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mzeros\u001b[39m\u001b[38;5;124m\"\u001b[39m:\n\u001b[0;32m    538\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m F\u001b[38;5;241m.\u001b[39mconv2d(\n\u001b[0;32m    539\u001b[0m         F\u001b[38;5;241m.\u001b[39mpad(\n\u001b[0;32m    540\u001b[0m             \u001b[38;5;28minput\u001b[39m, \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_reversed_padding_repeated_twice, mode\u001b[38;5;241m=\u001b[39m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mpadding_mode\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m    547\u001b[0m         \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mgroups,\n\u001b[0;32m    548\u001b[0m     )\n\u001b[1;32m--> 549\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mF\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mconv2d\u001b[49m\u001b[43m(\u001b[49m\n\u001b[0;32m    550\u001b[0m \u001b[43m    \u001b[49m\u001b[38;5;28;43minput\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mweight\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mbias\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mstride\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mpadding\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mdilation\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mgroups\u001b[49m\n\u001b[0;32m    551\u001b[0m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n",
            "\u001b[1;31mKeyboardInterrupt\u001b[0m: "
          ]
        }
      ],
      "source": [
        "def main():\n",
        "    #only_generate_csv = True  # <-- MUDA AQUI\n",
        "\n",
        "    structures = [\"Abdomen_\"] #,\"Femur_\", \"Head_\"] \n",
        "    birth_types = [\"Cesarean Birth\"]#, \"Vaginal Birth\"]\n",
        "    datasets = [\"test\"]#, \"test\"]\n",
        "    splits = [\"cv3\"] #[\"cv1\", \"cv2\",\"cv3\"]\n",
        "\n",
        "    #dfs_by_split = {split: {} for split in splits}  # dict de dicts\n",
        "\n",
        "    base_input = \"C:/Users/anale/OneDrive/Documentos/Universidade/TESE/image-dataset/dataset_images_{split}/{structure}/{dataset}/{birth_type}\"\n",
        "    base_output = \"C:/Users/anale/OneDrive/Documentos/Universidade/TESE/RESULTS/TARGETLAYERTESTE\"#HiRes_medvit_{split}_results/X_hires_medvit_{structure_clean}_{birth_type_short}_{dataset}_{split}\" \n",
        "    base_weight = \"C:/Users/anale/OneDrive/Documentos/Universidade/TESE/model_paths/MedViT_paths/{structure_clean}_{split}_medvit_pretrained_best-model.pth\"\n",
        "    #output_dir = \"C:/Users/anale/OneDrive/Documentos/Universidade/TESE/RESULTS/prediction_confidence_medvit_xlsx\"\n",
        "    #os.makedirs(output_dir, exist_ok=True)\n",
        "\n",
        "\n",
        "    for split in splits:\n",
        "        for structure in structures:\n",
        "            structure_clean = structure.rstrip(\"_\").lower()\n",
        "            for birth_type in birth_types:\n",
        "                birth_type_short = birth_type.split()[0].lower()  # 'cesarean' or 'vaginal'\n",
        "                for dataset in datasets:\n",
        "                    input_folder = base_input.format(split=split, structure=structure, birth_type=birth_type, dataset=dataset)\n",
        "                    output_folder = base_output.format(split=split, structure_clean=structure_clean, birth_type_short=birth_type_short, dataset=dataset)\n",
        "                    weight_path = base_weight.format(structure_clean=structure_clean, split=split)\n",
        "\n",
        "                    if not os.path.exists(weight_path):\n",
        "                        print(f\"[SKIPPED] Weight file does not exist: {weight_path}\")\n",
        "                        continue\n",
        "\n",
        "                    print(f\"Processing: {structure}, {birth_type}, {dataset}, {split}\")\n",
        "                    model = load_medvit_model(weight_path, num_classes=2)\n",
        "                    all_heatmaps, original_images = apply_gradcam_and_save(model, input_folder, output_folder)\n",
        "\n",
        "                    \"\"\"df = generate_prediction_table_only(\n",
        "                            model=model,\n",
        "                            input_folder=input_folder,\n",
        "                            split_name=split,\n",
        "                            structure=structure_clean,\n",
        "                            birth_type=birth_type_short,\n",
        "                            dataset=dataset\n",
        "                    )\n",
        "                    \n",
        "                    sheet_name = f\"{structure_clean}_{birth_type_short}_{dataset}\"[:31]\n",
        "                    dfs_by_split[split][sheet_name] = df\n",
        "\n",
        "    # === Guardar cada split como um ficheiro .xlsx ===\n",
        "    for split, sheet_dict in dfs_by_split.items():\n",
        "        excel_path = os.path.join(output_dir, f\"{split}.xlsx\")\n",
        "        with pd.ExcelWriter(excel_path, engine=\"openpyxl\") as writer:\n",
        "            for sheet_name, df in sheet_dict.items():\n",
        "                df.to_excel(writer, sheet_name=sheet_name, index=False)\n",
        "        print(f\"Guardado: {excel_path}\")\"\"\"\n",
        "\n",
        "    print(\"All Grad-CAM heatmaps were generated successfully.\")\n",
        "\n",
        "if __name__ == \"__main__\":\n",
        "    main() \n"
      ]
    }
  ],
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "display_name": "leonorjacob-tese",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.10.16"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
